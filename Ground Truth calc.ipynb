{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import timedelta\n",
    "from Classifier import ScorePredictor, balance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/movies/embeddings/amazon_small.pickle', 'rb') as handle:\n",
    "    embs, keys = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_year(embeddings, keys, year):\n",
    "    nth_year = [x for x in list(zip(embeddings, keys)) if keys[0][-1] + timedelta(days=365*year) < x[1][-1] < keys[0][-1] + timedelta(days=365*(year+1))] # gather amazon reviews of the third year only\n",
    "    nth_year = [list(t) for t in zip(*nth_year)]\n",
    "    nth_year[1] = [x[1] for x in nth_year[1]]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(nth_year[0], nth_year[1], test_size=0.33, random_state=42)\n",
    "    s = ScorePredictor()\n",
    "    s.train(X_train, y_train)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for outer_loop in range(0, 16):\n",
    "    predictor = train_on_year(embs, keys, outer_loop)\n",
    "    \n",
    "    accuracy = []\n",
    "    for year in range(16):\n",
    "        data = [x for x in list(zip(embs, keys)) if keys[0][-1] + timedelta(days=365*year) < x[1][-1] < keys[0][-1] + timedelta(days=365*(year+1))]\n",
    "        data = [list(t) for t in zip(*data)]\n",
    "        data[1] = [x[1] for x in data[1]]\n",
    "        X_test, y_test = balance(data[0], data[1])\n",
    "        accuracy.append(predictor.evaluate(X_test, y_test)[1])\n",
    "    results.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(results), cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.heatmap(np.array(results), linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(results[10]))\n",
    "plt.yticks(np.arange(0.1, 0.6, step=0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(results[11]))\n",
    "plt.yticks(np.arange(0.1, 0.6, step=0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(results[7]))\n",
    "plt.yticks(np.arange(0.1, 0.6, step=0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(results[6]))\n",
    "plt.yticks(np.arange(0.1, 0.6, step=0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
