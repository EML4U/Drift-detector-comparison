@InProceedings{2021DriftDetectDocEmb,
    author="Feldhans, Robert
        and Wilke, Adrian
        and Heindorf, Stefan
        and Shaker, Mohammad Hossein
        and Hammer, Barbara
        and Ngonga Ngomo, Axel-Cyrille
        and H{\"u}llermeier, Eyke",
    editor="Yin, Hujun
        and Camacho, David
        and Tino, Peter
        and Allmendinger, Richard
        and Tall{\'o}n-Ballesteros, Antonio J.
        and Tang, Ke
        and Cho, Sung-Bae
        and Novais, Paulo
        and Nascimento, Susana",
    title="Drift Detection in Text Data with Document Embeddings",
    booktitle="Intelligent Data Engineering and Automated Learning -- IDEAL 2021",
    year="2021",
    publisher="Springer International Publishing",
    address="Cham",
    pages="107--118",
    abstract="Collections of text documents such as product reviews and microblogs often evolve over time. In practice, however, classifiers trained on them are updated infrequently, leading to performance degradation over time.While approaches for automatic drift detection have been proposed, they were often designed for low-dimensional sensor data, and it is unclear how well they perform for state-of-the-art text classifiers based on high-dimensional document embeddings. In this paper, we empirically compare drift detectors on document embeddings on two benchmarking datasets with varying amounts of drift. Our results show that multivariate drift detectors based on the Kernel Two-Sample Test and Least-Squares Density Difference outperform univariate drift detectors based on the Kolmogorov-Smirnov Test. Moreover, our experiments show that current drift detectors perform better on smaller embedding dimensions.",
    isbn="978-3-030-91608-4",
    url = {https://doi.org/10.1007/978-3-030-91608-4_11}
}
