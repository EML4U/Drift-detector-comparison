{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores of injection experiments (**metric version C**)\n",
    "\n",
    "This rates the first results very high, but last results probably too low.\n",
    "\n",
    "Printed tables can be pasted at https://www.tablesgenerator.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = \"../data/results/\"\n",
    "evaluation_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter_diff_dist   ../data/results/twitter_diff_dist.pickle   <class 'tuple'>   3\n",
      "twitter_drift_induction   ../data/results/twitter_drift_induction.pickle   <class 'dict'>   3\n",
      "amazon_diff_classes   ../data/results/amazon_diff_classes.pickle   <class 'dict'>   3\n",
      "amazon_same_dist   ../data/results/amazon_same_dist.pickle   <class 'dict'>   3\n",
      "twitter_same_dist   ../data/results/twitter_same_dist.pickle   <class 'dict'>   3\n",
      "twitter_diff_classes   ../data/results/twitter_diff_classes.pickle   <class 'dict'>   3\n",
      "amazon_drift_induction   ../data/results/amazon_drift_induction.pickle   <class 'dict'>   3\n"
     ]
    }
   ],
   "source": [
    "results_meta = {}\n",
    "\n",
    "# get files and ids\n",
    "for name in listdir(results_directory):\n",
    "    path = join(results_directory, name)\n",
    "    if isfile(path):\n",
    "        id = name[:-7]\n",
    "        results_meta[id] = {\"result_pickle\":path}\n",
    "\n",
    "# add data\n",
    "for key in results_meta:\n",
    "    with open(results_meta[key][\"result_pickle\"], 'rb') as handle:\n",
    "        results_meta[key][\"data\"] = pickle.load(handle)\n",
    "\n",
    "# print info\n",
    "for key in results_meta: \n",
    "    print(\n",
    "        key, \" \",\n",
    "        results_meta[key][\"result_pickle\"], \" \",\n",
    "        type(results_meta[key][\"data\"]), \" \",\n",
    "        len(results_meta[key][\"data\"])\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results: twitter_drift_induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config from notebook\n",
    "permutations = 10\n",
    "modes = ['bert_768', 'bow_50', 'bow_768']\n",
    "target_percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "detectors = {\n",
    "    'csdd': 'CosineSimilarityDriftDetector()',\n",
    "    'kts' : 'KernelTwoSampleDriftDetector()',\n",
    "    'aks' : 'AlibiKSDetector()',\n",
    "    'ammd': 'AlibiMMDDetector()',\n",
    "    'lsdd': 'AlibiLSDDDetector()',\n",
    "    'cdbd': 'CDBDDetector()',\n",
    "}\n",
    "result_pickle = results_meta[\"twitter_drift_induction\"][\"result_pickle\"]\n",
    "try:\n",
    "    del results\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading result pickle:  ../data/results/twitter_drift_induction.pickle\n",
      "bert_768\n",
      "bow_50\n",
      "bow_768\n"
     ]
    }
   ],
   "source": [
    "evaluation_data[\"twitter\"] = {}\n",
    "\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    print('Loading result pickle: ', result_pickle)\n",
    "    with open(result_pickle, 'rb') as handle:\n",
    "        results = pickle.load(handle)    \n",
    "\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    plot_data = {}\n",
    "       \n",
    "    for detector in detectors:\n",
    "        plot_data[detector] = []\n",
    "        for n in range(len(results[mode][detector]['predictions'][0])):\n",
    "            nth_entries = [results[mode][detector]['predictions'][i][n] for i in range(permutations)]\n",
    "            plot_data[detector].append(np.mean(nth_entries))\n",
    "\n",
    "    evaluation_data[\"twitter\"][mode] = plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results: amazon_drift_induction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config from notebook\n",
    "permutations = 10\n",
    "modes = ['bert_768', 'bow_50', 'bow_768']\n",
    "target_percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "detectors = {\n",
    "    'csdd': \"\",\n",
    "    'kts' : \"\",\n",
    "    'aks' : \"\",\n",
    "    'ammd': \"\",\n",
    "    'lsdd': \"\",\n",
    "    'cdbd': \"\",\n",
    "}\n",
    "result_pickle = results_meta[\"amazon_drift_induction\"][\"result_pickle\"]\n",
    "try:\n",
    "    del results\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading result pickle:  ../data/results/amazon_drift_induction.pickle\n",
      "bert_768\n",
      "bow_50\n",
      "bow_768\n"
     ]
    }
   ],
   "source": [
    "evaluation_data[\"amazon\"] = {}\n",
    "\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    print('Loading result pickle: ', result_pickle)\n",
    "    with open(result_pickle, 'rb') as handle:\n",
    "        results = pickle.load(handle)    \n",
    "\n",
    "# plot\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    plot_data = {}\n",
    "       \n",
    "    for detector in detectors:\n",
    "        plot_data[detector] = []\n",
    "        for n in range(len(results[mode][detector]['predictions'][0])):\n",
    "            nth_entries = [results[mode][detector]['predictions'][i][n] for i in range(permutations)]\n",
    "            plot_data[detector].append(np.mean(nth_entries))\n",
    "            \n",
    "    evaluation_data[\"amazon\"][mode] = plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of conducted experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_words_percentage [0.    0.025 0.05  0.075 0.1   0.125 0.15  0.175 0.2   0.225 0.25  0.275\n",
      " 0.3   0.325 0.35  0.375 0.4   0.425 0.45  0.475 0.5  ]\n"
     ]
    }
   ],
   "source": [
    "target_percentages = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "negative_words_percentage = np.divide(target_percentages, 2)\n",
    "print(\"negative_words_percentage\", negative_words_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add comparison detector values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data['test'] = {}\n",
    "evaluation_data['test']['testmode'] = {}\n",
    "\n",
    "fake_predictions = [0] * 21\n",
    "fake_predictions[0] = 1\n",
    "evaluation_data['test']['testmode']['perfect'] = fake_predictions\n",
    "\n",
    "fake_predictions = [1] * 21\n",
    "fake_predictions[0] = 0\n",
    "evaluation_data['test']['testmode']['bad'] = fake_predictions\n",
    "\n",
    "fake_predictions = negative_words_percentage\n",
    "fake_predictions[0] = .012\n",
    "fake_predictions = np.divide(.01, fake_predictions)\n",
    "evaluation_data['test']['testmode']['fake'] = fake_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter bert_768 csdd 21    [0.9998 0.9998 0.9998 0.9997] ... [0.9998 0.9998 0.9998 0.9997]\n",
      "twitter bert_768 kts 21    [0.591  0.5846 0.538  0.4364] ... [0.591  0.5846 0.538  0.4364]\n",
      "twitter bert_768 aks 21    [0.5178 0.5154 0.5094 0.5009] ... [0.5178 0.5154 0.5094 0.5009]\n",
      "twitter bert_768 ammd 21    [0.547 0.532 0.453 0.347] ... [0.547 0.532 0.453 0.347]\n",
      "twitter bert_768 lsdd 21    [0.572 0.518 0.47  0.374] ... [0.572 0.518 0.47  0.374]\n",
      "twitter bert_768 cdbd 21    [0.2411 0.2306 0.2263 0.2172] ... [0.2411 0.2306 0.2263 0.2172]\n",
      "twitter bow_50 csdd 21    [0.9951 0.9945 0.9934 0.9918] ... [0.9951 0.9945 0.9934 0.9918]\n",
      "twitter bow_50 kts 21    [0.3424 0.2188 0.0786 0.0164] ... [0.3424 0.2188 0.0786 0.0164]\n",
      "twitter bow_50 aks 21    [0.4931 0.4776 0.4279 0.3877] ... [0.4931 0.4776 0.4279 0.3877]\n",
      "twitter bow_50 ammd 21    [0.383 0.22  0.087 0.013] ... [0.383 0.22  0.087 0.013]\n",
      "twitter bow_50 lsdd 21    [0.443 0.294 0.141 0.049] ... [0.443 0.294 0.141 0.049]\n",
      "twitter bow_50 cdbd 21    [0.2029 0.2144 0.2253 0.2124] ... [0.2029 0.2144 0.2253 0.2124]\n",
      "twitter bow_768 csdd 21    [0.9236 0.9235 0.9216 0.9161] ... [0.9236 0.9235 0.9216 0.9161]\n",
      "twitter bow_768 kts 21    [0.465  0.3772 0.1494 0.0172] ... [0.465  0.3772 0.1494 0.0172]\n",
      "twitter bow_768 aks 21    [0.4986 0.4889 0.4653 0.4328] ... [0.4986 0.4889 0.4653 0.4328]\n",
      "twitter bow_768 ammd 21    [0.436 0.281 0.123 0.054] ... [0.436 0.281 0.123 0.054]\n",
      "twitter bow_768 lsdd 21    [0.43  0.287 0.212 0.171] ... [0.43  0.287 0.212 0.171]\n",
      "twitter bow_768 cdbd 21    [0.285  0.2546 0.291  0.2814] ... [0.285  0.2546 0.291  0.2814]\n",
      "amazon bert_768 csdd 21    [0.9993 0.9993 0.9992 0.9991] ... [0.9993 0.9993 0.9992 0.9991]\n",
      "amazon bert_768 kts 21    [0.7208 0.6936 0.6286 0.5108] ... [0.7208 0.6936 0.6286 0.5108]\n",
      "amazon bert_768 aks 21    [0.5498 0.5437 0.5309 0.5109] ... [0.5498 0.5437 0.5309 0.5109]\n",
      "amazon bert_768 ammd 21    [0.742 0.736 0.643 0.523] ... [0.742 0.736 0.643 0.523]\n",
      "amazon bert_768 lsdd 21    [0.721 0.703 0.647 0.546] ... [0.721 0.703 0.647 0.546]\n",
      "amazon bert_768 cdbd 21    [0. 0. 0. 0.] ... [0. 0. 0. 0.]\n",
      "amazon bow_50 csdd 21    [0.9974 0.9973 0.9971 0.9968] ... [0.9974 0.9973 0.9971 0.9968]\n",
      "amazon bow_50 kts 21    [0.5798 0.5368 0.427  0.2852] ... [0.5798 0.5368 0.427  0.2852]\n",
      "amazon bow_50 aks 21    [0.5158 0.5121 0.5065 0.4979] ... [0.5158 0.5121 0.5065 0.4979]\n",
      "amazon bow_50 ammd 21    [0.531 0.506 0.387 0.275] ... [0.531 0.506 0.387 0.275]\n",
      "amazon bow_50 lsdd 21    [0.615 0.534 0.462 0.315] ... [0.615 0.534 0.462 0.315]\n",
      "amazon bow_50 cdbd 21    [0. 0. 0. 0.] ... [0. 0. 0. 0.]\n",
      "amazon bow_768 csdd 21    [0.9953 0.9953 0.9952 0.9952] ... [0.9953 0.9953 0.9952 0.9952]\n",
      "amazon bow_768 kts 21    [0.444  0.4538 0.3696 0.347 ] ... [0.444  0.4538 0.3696 0.347 ]\n",
      "amazon bow_768 aks 21    [0.5128 0.5121 0.5097 0.5058] ... [0.5128 0.5121 0.5097 0.5058]\n",
      "amazon bow_768 ammd 21    [0.557 0.553 0.502 0.446] ... [0.557 0.553 0.502 0.446]\n",
      "amazon bow_768 lsdd 21    [0.493 0.471 0.498 0.464] ... [0.493 0.471 0.498 0.464]\n",
      "amazon bow_768 cdbd 21    [0. 0. 0. 0.] ... [0. 0. 0. 0.]\n",
      "test testmode perfect 21    [1 0 0 0] ... [1 0 0 0]\n",
      "test testmode bad 21    [0 1 1 1] ... [0 1 1 1]\n",
      "test testmode fake 21    [0.8333 0.4    0.2    0.1333] ... [0.8333 0.4    0.2    0.1333]\n"
     ]
    }
   ],
   "source": [
    "for dataset in evaluation_data:\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            first = np.round(evaluation_data[dataset][mode][detector][:4], 4)\n",
    "            last = np.round(evaluation_data[dataset][mode][detector][0:4], 4)\n",
    "            print(dataset, mode, detector, len(evaluation_data[dataset][mode][detector]), \"  \", first, \"...\", last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric_pow(negative_words_percentage, p_values, factor_penalty, power_base, print_info):\n",
    "    \n",
    "    # remove first element (no injected drift)\n",
    "    neg_words_perc = negative_words_percentage[1:]\n",
    "    p_vals = p_values[1:]\n",
    "        \n",
    "    # Scores 0 (bad) to 1 (good)\n",
    "    scores = []\n",
    "    for i in range(len(p_vals)):\n",
    "        scores.append(1 - p_vals[i])\n",
    "    if(print_info):\n",
    "        print(\" difference score \", round(np.sum(scores), 4))\n",
    "    \n",
    "    # No injected drift in first element\n",
    "    # High penalty for low p-value\n",
    "    penalty = (1 - p_values[0]) * factor_penalty\n",
    "    for i in range(len(scores)):\n",
    "        scores[i] = (scores[i] - penalty)\n",
    "    if(print_info):\n",
    "        print(\" penalty \", round(penalty, 4), \"= 1 -\", round(p_values[0], 4))\n",
    "        print(round(np.sum(scores), 4), \"penalty score\")\n",
    "        \n",
    "    # Earlier drift detection is better (sensitivity)\n",
    "    sum_rating = 0\n",
    "    for i in range(len(scores)):\n",
    "        rating = pow(power_base, 1/neg_words_perc[i])\n",
    "        sum_rating += rating\n",
    "        scores[i] = scores[i] * rating\n",
    "    \n",
    "    if(print_info):\n",
    "        print(\" scores \", np.round(scores, 2))\n",
    "        print(\" sum_rating \", round(sum_rating, 4))\n",
    "        print(\" result \", round(np.sum(scores) / sum_rating, 4))\n",
    "    \n",
    "    return np.sum(scores) / sum_rating\n",
    "\n",
    "\n",
    "def get_label(name):\n",
    "    mappings = {\n",
    "        \"cdbd\" : \"CDBD\",\n",
    "        \"csdd\" : \"CosSim\",\n",
    "        \"kts\" : \"KTS\",\n",
    "        \"aks\" : \"KS\",\n",
    "        \"lsdd\" : \"LSDD\",\n",
    "        \"ammd\" : \"MMD\",\n",
    "        \n",
    "        \"twitterbert_768\" : \"Twitter, BERT-768\",\n",
    "        \"twitterbow_50\"   : \"Twitter, BoW-50  \",\n",
    "        \"twitterbow_768\"  : \"Twitter, BoW-768 \",\n",
    "        \"amazonbert_768\"  : \"Amazon,  BERT-768\",\n",
    "        \"amazonbow_50\"    : \"Amazon,  BoW-50  \",\n",
    "        \"amazonbow_768\"   : \"Amazon,  BoW-768 \",\n",
    "    }\n",
    "    if(name in mappings):\n",
    "        return mappings[name]\n",
    "    else:\n",
    "        print(\"Unknown:\", name)\n",
    "        return name\n",
    "\n",
    "\n",
    "def get_sorted_detectors(detector_keys):\n",
    "    labels = {}\n",
    "    for detector in detectors:\n",
    "        labels[get_label(detector)] = detector\n",
    "    sorted_ = []\n",
    "    for detector in sorted(labels.keys()):\n",
    "        sorted_.append(labels[detector])\n",
    "    return sorted_\n",
    "\n",
    "\n",
    "def format_float(value):\n",
    "    rounded = np.round(value, 4)\n",
    "    if(rounded == 0): # handle -0.0\n",
    "        rounded = 0\n",
    "    return (format(rounded, '.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_textbf = True\n",
    "best_marker_start = \"\\\\textbf{\"\n",
    "best_marker_end = \"}\"\n",
    "best_marker_start = \"⬛\"\n",
    "best_marker_end = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (with penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores_with_penalty = True\n",
    "\n",
    "scores = {}\n",
    "for dataset in evaluation_data:\n",
    "    scores[dataset] = {}\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        scores[dataset][mode] = {}\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            scores[dataset][mode][detector] = eval_metric_pow(negative_words_percentage, evaluation_data[dataset][mode][detector], 1, 2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon': {'bert_768': {'aks': 0.006043029549983538,\n",
      "                         'ammd': 0.006000091330780542,\n",
      "                         'cdbd': 0.0,\n",
      "                         'csdd': 5.501515712396836e-05,\n",
      "                         'kts': 0.027200064300705467,\n",
      "                         'lsdd': 0.018000041219333688},\n",
      "            'bow_50': {'aks': 0.003643577894274681,\n",
      "                       'ammd': 0.025000116259637672,\n",
      "                       'cdbd': 0.0,\n",
      "                       'csdd': 9.965912989239957e-05,\n",
      "                       'kts': 0.04300010769702112,\n",
      "                       'lsdd': 0.08100007228193422},\n",
      "            'bow_768': {'aks': 0.0007441663713498737,\n",
      "                        'ammd': 0.004000049987231799,\n",
      "                        'cdbd': -6.431310448433687e-11,\n",
      "                        'csdd': 2.1278925353253043e-05,\n",
      "                        'kts': -0.00979991831936586,\n",
      "                        'lsdd': 0.021999981726778296}},\n",
      " 'test': {'testmode': {'bad': -0.9999999999999998,\n",
      "                       'fake': 0.4333335270178459,\n",
      "                       'perfect': 0.9999999999999998}},\n",
      " 'twitter': {'bert_768': {'aks': 0.0024774133489263972,\n",
      "                          'ammd': 0.015000077578348973,\n",
      "                          'cdbd': 0.01041386569050983,\n",
      "                          'csdd': 5.06640689814304e-06,\n",
      "                          'kts': 0.006400046332651051,\n",
      "                          'lsdd': 0.054000042229840936},\n",
      "             'bow_50': {'aks': 0.01552589616719246,\n",
      "                        'ammd': 0.1630001290944053,\n",
      "                        'cdbd': -0.011507534365201402,\n",
      "                        'csdd': 0.0006063590704283255,\n",
      "                        'kts': 0.12360013591402877,\n",
      "                        'lsdd': 0.14900014452530477},\n",
      "             'bow_768': {'aks': 0.009642773281203046,\n",
      "                         'ammd': 0.1550001531976559,\n",
      "                         'cdbd': 0.03040296539031283,\n",
      "                         'csdd': 0.0001001973307892541,\n",
      "                         'kts': 0.08780022116265193,\n",
      "                         'lsdd': 0.14300006931617595}}}\n"
     ]
    }
   ],
   "source": [
    "if(print_scores_with_penalty):\n",
    "    pprint.pprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset, Model    , CDBD   , CosSim , KS     , KTS    , LSDD   , MMD    , $\\varnothing$ , \n",
      "Amazon,  BoW-50   , 0.0000 , 0.0001 , 0.0036 , 0.0430 , ⬛0.0810 , 0.0250 , 0.0255 , \n",
      "Amazon,  BoW-768  , 0.0000 , 0.0000 , 0.0007 , -0.0098 , ⬛0.0220 , 0.0040 , 0.0028 , \n",
      "Amazon,  BERT-768 , 0.0000 , 0.0001 , 0.0060 , ⬛0.0272 , 0.0180 , 0.0060 , 0.0095 , \n",
      "Twitter, BoW-50   , -0.0115 , 0.0006 , 0.0155 , 0.1236 , 0.1490 , ⬛0.1630 , 0.0734 , \n",
      "Twitter, BoW-768  , 0.0304 , 0.0001 , 0.0096 , 0.0878 , 0.1430 , ⬛0.1550 , 0.0710 , \n",
      "Twitter, BERT-768 , 0.0104 , 0.0000 , 0.0025 , 0.0064 , ⬛0.0540 , 0.0150 , 0.0147 , \n",
      "$\\varnothing$     ,        , 0.0049 , 0.0001 , 0.0063 , 0.0464 , 0.0778 , 0.0613 , "
     ]
    }
   ],
   "source": [
    "sorted_detectors = get_sorted_detectors(scores[\"twitter\"][\"bert_768\"])\n",
    "sorted_datasets = sorted(scores.keys())\n",
    "sorted_modes = ['bow_50', 'bow_768', 'bert_768']\n",
    "\n",
    "# Get values to compute means\n",
    "s = {}\n",
    "c = {}\n",
    "sd = {}\n",
    "cd = {}\n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            sd[detector] = sd.get(detector,0) + score\n",
    "            s[dataset+mode] = s.get(dataset+mode,0) + score\n",
    "            cd[detector] = cd.get(detector,0) + 1\n",
    "            c[dataset+mode] = c.get(dataset+mode,0) + 1\n",
    "\n",
    "\n",
    "            \n",
    "end=\" , \"\n",
    "print(\"Dataset, Model   \", end=end)\n",
    "for detector in sorted_detectors:\n",
    "    #print(get_label(detector), end=end)\n",
    "    print(\"{:<6}\".format(get_label(detector)), end=end)\n",
    "print(\"$\\\\varnothing$\", end=end) # ∅ $\\varnothing$\n",
    "    \n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        print()\n",
    "        print(get_label(dataset+mode), end=end)\n",
    "        \n",
    "        max_detector = None\n",
    "        max_score = -2\n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            if(score > max_score):\n",
    "                max_score = score\n",
    "                max_detector = detector\n",
    "                \n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_start, end=\"\") # backslash could not be parsed in latex tool\n",
    "            print(format_float(score), end=\"\")\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_end, end=\"\")\n",
    "                \n",
    "            print(\"\", end=end)\n",
    "            \n",
    "        print(format_float(s[dataset+mode]/c[dataset+mode]), end=end)\n",
    "\n",
    "print()\n",
    "print('$\\\\varnothing$     ,       ', end=end) # ∅ $\\varnothing$\n",
    "for detector in sorted_detectors:\n",
    "    print(format_float(sd[detector]/cd[detector]), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    pprint.pprint(s)\n",
    "    pprint.pprint(c)\n",
    "    pprint.pprint(sd)\n",
    "    pprint.pprint(cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (without penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores_without_penalty = True\n",
    "\n",
    "scoresNoPenalty = {}\n",
    "for dataset in evaluation_data:\n",
    "    scoresNoPenalty[dataset] = {}\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        scoresNoPenalty[dataset][mode] = {}\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            scoresNoPenalty[dataset][mode][detector] = eval_metric_pow(negative_words_percentage, evaluation_data[dataset][mode][detector], 0, 2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon': {'bert_768': {'aks': 0.4562623031171832,\n",
      "                         'ammd': 0.26400009133078056,\n",
      "                         'cdbd': 0.9999999999999998,\n",
      "                         'csdd': 0.0007308126195873471,\n",
      "                         'kts': 0.30640006430070543,\n",
      "                         'lsdd': 0.29700007018719105},\n",
      "            'bow_50': {'aks': 0.4878900106754941,\n",
      "                       'ammd': 0.4940001162596377,\n",
      "                       'cdbd': 0.9999999999999998,\n",
      "                       'csdd': 0.0027174951284275554,\n",
      "                       'kts': 0.46320010769702114,\n",
      "                       'lsdd': 0.4660000910573973},\n",
      "            'bow_768': {'aks': 0.48791039228153654,\n",
      "                        'ammd': 0.4470000499872317,\n",
      "                        'cdbd': 0.9999999999272705,\n",
      "                        'csdd': 0.0046895147041618465,\n",
      "                        'kts': 0.5462000816806339,\n",
      "                        'lsdd': 0.5289999914423353}},\n",
      " 'test': {'testmode': {'bad': 0.0,\n",
      "                       'fake': 0.6000001936845125,\n",
      "                       'perfect': 0.9999999999999998}},\n",
      " 'twitter': {'bert_768': {'aks': 0.48464739912010557,\n",
      "                          'ammd': 0.4680000775783489,\n",
      "                          'cdbd': 0.7693519185553023,\n",
      "                          'csdd': 0.00023460389392817235,\n",
      "                          'kts': 0.4154000463326511,\n",
      "                          'lsdd': 0.4820000542699791},\n",
      "             'bow_50': {'aks': 0.5223831125253774,\n",
      "                        'ammd': 0.7800001290944052,\n",
      "                        'cdbd': 0.7855701442894233,\n",
      "                        'csdd': 0.005534828728326275,\n",
      "                        'kts': 0.7812001359140287,\n",
      "                        'lsdd': 0.7060001574073586},\n",
      "             'bow_768': {'aks': 0.5110539132462605,\n",
      "                         'ammd': 0.7190001531976558,\n",
      "                         'cdbd': 0.7453868130556252,\n",
      "                         'csdd': 0.07647121144898382,\n",
      "                         'kts': 0.6228002211626519,\n",
      "                         'lsdd': 0.7130000806038054}}}\n"
     ]
    }
   ],
   "source": [
    "if(print_scores_without_penalty):\n",
    "    pprint.pprint(scoresNoPenalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset, Model    , CDBD   , CosSim , KS     , KTS    , LSDD   , MMD    , $\\varnothing$ , \n",
      "Amazon,  BoW-50   , 1.0000 , 0.0027 , 0.4879 , 0.4632 , 0.4660 , ⬛0.4940 , 0.4856 , \n",
      "Amazon,  BoW-768  , 1.0000 , 0.0047 , 0.4879 , ⬛0.5462 , 0.5290 , 0.4470 , 0.5025 , \n",
      "Amazon,  BERT-768 , 1.0000 , 0.0007 , ⬛0.4563 , 0.3064 , 0.2970 , 0.2640 , 0.3874 , \n",
      "Twitter, BoW-50   , 0.7856 , 0.0055 , 0.5224 , ⬛0.7812 , 0.7060 , 0.7800 , 0.5968 , \n",
      "Twitter, BoW-768  , 0.7454 , 0.0765 , 0.5111 , 0.6228 , 0.7130 , ⬛0.7190 , 0.5646 , \n",
      "Twitter, BERT-768 , 0.7694 , 0.0002 , ⬛0.4846 , 0.4154 , 0.4820 , 0.4680 , 0.4366 , \n",
      "$\\varnothing$     ,        , 0.8834 , 0.0151 , 0.4917 , 0.5225 , 0.5322 , 0.5287 , "
     ]
    }
   ],
   "source": [
    "sorted_detectors = get_sorted_detectors(scores[\"twitter\"][\"bert_768\"])\n",
    "sorted_datasets = sorted(scores.keys())\n",
    "sorted_modes = ['bow_50', 'bow_768', 'bert_768']\n",
    "\n",
    "# Get values to compute means\n",
    "s = {}\n",
    "c = {}\n",
    "sd = {}\n",
    "cd = {}\n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        for detector in sorted_detectors:\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            sd[detector] = sd.get(detector,0) + score\n",
    "            s[dataset+mode] = s.get(dataset+mode,0) + score\n",
    "            cd[detector] = cd.get(detector,0) + 1\n",
    "            c[dataset+mode] = c.get(dataset+mode,0) + 1\n",
    "\n",
    "\n",
    "            \n",
    "end=\" , \"\n",
    "print(\"Dataset, Model   \", end=end)\n",
    "for detector in sorted_detectors:\n",
    "    print(\"{:<6}\".format(get_label(detector)), end=end)\n",
    "print(\"$\\\\varnothing$\", end=end) # ∅ $\\varnothing$\n",
    "    \n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        print()\n",
    "        print(get_label(dataset+mode), end=end)\n",
    "        \n",
    "        max_detector = None\n",
    "        max_score = -2\n",
    "        for detector in sorted_detectors:\n",
    "            if(detector == \"cdbd\"): # exclude from max scores\n",
    "                continue\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            if(score > max_score):\n",
    "                max_score = score\n",
    "                max_detector = detector\n",
    "        \n",
    "        for detector in sorted_detectors:\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_start, end=\"\") # backslash could not be parsed in latex tool\n",
    "            print(format_float(score), end=\"\")\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_end, end=\"\")\n",
    "            print(\"\", end=end)\n",
    "            \n",
    "        print(format_float(s[dataset+mode]/c[dataset+mode]), end=end)\n",
    "\n",
    "print()\n",
    "print('$\\\\varnothing$     ,       ', end=end) # ∅ $\\varnothing$\n",
    "for detector in sorted_detectors:\n",
    "    print(format_float(sd[detector]/cd[detector]), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    pprint.pprint(s)\n",
    "    pprint.pprint(c)\n",
    "    pprint.pprint(sd)\n",
    "    pprint.pprint(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project)",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

