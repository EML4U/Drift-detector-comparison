{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores of injection experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = \"../data/results/\"\n",
    "evaluation_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter_diff_dist   ../data/results/twitter_diff_dist.pickle   <class 'tuple'>   3\n",
      "twitter_drift_induction   ../data/results/twitter_drift_induction.pickle   <class 'dict'>   3\n",
      "amazon_diff_classes   ../data/results/amazon_diff_classes.pickle   <class 'dict'>   3\n",
      "amazon_same_dist   ../data/results/amazon_same_dist.pickle   <class 'dict'>   3\n",
      "twitter_same_dist   ../data/results/twitter_same_dist.pickle   <class 'dict'>   3\n",
      "twitter_diff_classes   ../data/results/twitter_diff_classes.pickle   <class 'dict'>   3\n",
      "amazon_drift_induction   ../data/results/amazon_drift_induction.pickle   <class 'dict'>   3\n"
     ]
    }
   ],
   "source": [
    "results_meta = {}\n",
    "\n",
    "# get files and ids\n",
    "for name in listdir(results_directory):\n",
    "    path = join(results_directory, name)\n",
    "    if isfile(path):\n",
    "        id = name[:-7]\n",
    "        results_meta[id] = {\"result_pickle\":path}\n",
    "\n",
    "# add data\n",
    "for key in results_meta:\n",
    "    with open(results_meta[key][\"result_pickle\"], 'rb') as handle:\n",
    "        results_meta[key][\"data\"] = pickle.load(handle)\n",
    "\n",
    "# print info\n",
    "for key in results_meta: \n",
    "    print(\n",
    "        key, \" \",\n",
    "        results_meta[key][\"result_pickle\"], \" \",\n",
    "        type(results_meta[key][\"data\"]), \" \",\n",
    "        len(results_meta[key][\"data\"])\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results: twitter_drift_induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config from notebook\n",
    "permutations = 10\n",
    "modes = ['bert_768', 'bow_50', 'bow_768']\n",
    "target_percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "detectors = {\n",
    "    'csdd': 'CosineSimilarityDriftDetector()',\n",
    "    'kts' : 'KernelTwoSampleDriftDetector()',\n",
    "    'aks' : 'AlibiKSDetector()',\n",
    "    'ammd': 'AlibiMMDDetector()',\n",
    "    'lsdd': 'AlibiLSDDDetector()',\n",
    "    'cdbd': 'CDBDDetector()',\n",
    "}\n",
    "result_pickle = results_meta[\"twitter_drift_induction\"][\"result_pickle\"]\n",
    "try:\n",
    "    del results\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading result pickle:  ../data/results/twitter_drift_induction.pickle\n",
      "bert_768\n",
      "bow_50\n",
      "bow_768\n"
     ]
    }
   ],
   "source": [
    "evaluation_data[\"twitter\"] = {}\n",
    "\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    print('Loading result pickle: ', result_pickle)\n",
    "    with open(result_pickle, 'rb') as handle:\n",
    "        results = pickle.load(handle)    \n",
    "\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    plot_data = {}\n",
    "       \n",
    "    for detector in detectors:\n",
    "        plot_data[detector] = []\n",
    "        for n in range(len(results[mode][detector]['predictions'][0])):\n",
    "            nth_entries = [results[mode][detector]['predictions'][i][n] for i in range(permutations)]\n",
    "            plot_data[detector].append(np.mean(nth_entries))\n",
    "\n",
    "    evaluation_data[\"twitter\"][mode] = plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results: amazon_drift_induction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config from notebook\n",
    "permutations = 10\n",
    "modes = ['bert_768', 'bow_50', 'bow_768']\n",
    "target_percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "detectors = {\n",
    "    'csdd': \"\",\n",
    "    'kts' : \"\",\n",
    "    'aks' : \"\",\n",
    "    'ammd': \"\",\n",
    "    'lsdd': \"\",\n",
    "    'cdbd': \"\",\n",
    "}\n",
    "result_pickle = results_meta[\"amazon_drift_induction\"][\"result_pickle\"]\n",
    "try:\n",
    "    del results\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading result pickle:  ../data/results/amazon_drift_induction.pickle\n",
      "bert_768\n",
      "bow_50\n",
      "bow_768\n"
     ]
    }
   ],
   "source": [
    "evaluation_data[\"amazon\"] = {}\n",
    "\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    print('Loading result pickle: ', result_pickle)\n",
    "    with open(result_pickle, 'rb') as handle:\n",
    "        results = pickle.load(handle)    \n",
    "\n",
    "# plot\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    plot_data = {}\n",
    "       \n",
    "    for detector in detectors:\n",
    "        plot_data[detector] = []\n",
    "        for n in range(len(results[mode][detector]['predictions'][0])):\n",
    "            nth_entries = [results[mode][detector]['predictions'][i][n] for i in range(permutations)]\n",
    "            plot_data[detector].append(np.mean(nth_entries))\n",
    "            \n",
    "    evaluation_data[\"amazon\"][mode] = plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of conducted experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_words_percentage [0.    0.025 0.05  0.075 0.1   0.125 0.15  0.175 0.2   0.225 0.25  0.275\n",
      " 0.3   0.325 0.35  0.375 0.4   0.425 0.45  0.475 0.5  ]\n"
     ]
    }
   ],
   "source": [
    "target_percentages = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "negative_words_percentage = np.divide(target_percentages, 2)\n",
    "print(\"negative_words_percentage\", negative_words_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add comparison detector values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data['test'] = {}\n",
    "evaluation_data['test']['testmode'] = {}\n",
    "\n",
    "fake_predictions = [0] * 21\n",
    "fake_predictions[0] = 1\n",
    "evaluation_data['test']['testmode']['perfect'] = fake_predictions\n",
    "\n",
    "fake_predictions = [1] * 21\n",
    "fake_predictions[0] = 0\n",
    "evaluation_data['test']['testmode']['bad'] = fake_predictions\n",
    "\n",
    "fake_predictions = negative_words_percentage\n",
    "fake_predictions[0] = .012\n",
    "fake_predictions = np.divide(.01, fake_predictions)\n",
    "evaluation_data['test']['testmode']['fake'] = fake_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter bert_768 csdd 21    [0.9998 0.9998 0.9998 0.9997] ... [0.9998 0.9998 0.9998 0.9997]\n",
      "twitter bert_768 kts 21    [0.591  0.5846 0.538  0.4364] ... [0.591  0.5846 0.538  0.4364]\n",
      "twitter bert_768 aks 21    [0.5178 0.5154 0.5094 0.5009] ... [0.5178 0.5154 0.5094 0.5009]\n",
      "twitter bert_768 ammd 21    [0.547 0.532 0.453 0.347] ... [0.547 0.532 0.453 0.347]\n",
      "twitter bert_768 lsdd 21    [0.572 0.518 0.47  0.374] ... [0.572 0.518 0.47  0.374]\n",
      "twitter bert_768 cdbd 21    [0.2411 0.2306 0.2263 0.2172] ... [0.2411 0.2306 0.2263 0.2172]\n",
      "twitter bow_50 csdd 21    [0.9951 0.9945 0.9934 0.9918] ... [0.9951 0.9945 0.9934 0.9918]\n",
      "twitter bow_50 kts 21    [0.3424 0.2188 0.0786 0.0164] ... [0.3424 0.2188 0.0786 0.0164]\n",
      "twitter bow_50 aks 21    [0.4931 0.4776 0.4279 0.3877] ... [0.4931 0.4776 0.4279 0.3877]\n",
      "twitter bow_50 ammd 21    [0.383 0.22  0.087 0.013] ... [0.383 0.22  0.087 0.013]\n",
      "twitter bow_50 lsdd 21    [0.443 0.294 0.141 0.049] ... [0.443 0.294 0.141 0.049]\n",
      "twitter bow_50 cdbd 21    [0.2029 0.2144 0.2253 0.2124] ... [0.2029 0.2144 0.2253 0.2124]\n",
      "twitter bow_768 csdd 21    [0.9236 0.9235 0.9216 0.9161] ... [0.9236 0.9235 0.9216 0.9161]\n",
      "twitter bow_768 kts 21    [0.465  0.3772 0.1494 0.0172] ... [0.465  0.3772 0.1494 0.0172]\n",
      "twitter bow_768 aks 21    [0.4986 0.4889 0.4653 0.4328] ... [0.4986 0.4889 0.4653 0.4328]\n",
      "twitter bow_768 ammd 21    [0.436 0.281 0.123 0.054] ... [0.436 0.281 0.123 0.054]\n",
      "twitter bow_768 lsdd 21    [0.43  0.287 0.212 0.171] ... [0.43  0.287 0.212 0.171]\n",
      "twitter bow_768 cdbd 21    [0.285  0.2546 0.291  0.2814] ... [0.285  0.2546 0.291  0.2814]\n",
      "amazon bert_768 csdd 21    [0.9993 0.9993 0.9992 0.9991] ... [0.9993 0.9993 0.9992 0.9991]\n",
      "amazon bert_768 kts 21    [0.7208 0.6936 0.6286 0.5108] ... [0.7208 0.6936 0.6286 0.5108]\n",
      "amazon bert_768 aks 21    [0.5498 0.5437 0.5309 0.5109] ... [0.5498 0.5437 0.5309 0.5109]\n",
      "amazon bert_768 ammd 21    [0.742 0.736 0.643 0.523] ... [0.742 0.736 0.643 0.523]\n",
      "amazon bert_768 lsdd 21    [0.721 0.703 0.647 0.546] ... [0.721 0.703 0.647 0.546]\n",
      "amazon bert_768 cdbd 21    [0. 0. 0. 0.] ... [0. 0. 0. 0.]\n",
      "amazon bow_50 csdd 21    [0.9974 0.9973 0.9971 0.9968] ... [0.9974 0.9973 0.9971 0.9968]\n",
      "amazon bow_50 kts 21    [0.5798 0.5368 0.427  0.2852] ... [0.5798 0.5368 0.427  0.2852]\n",
      "amazon bow_50 aks 21    [0.5158 0.5121 0.5065 0.4979] ... [0.5158 0.5121 0.5065 0.4979]\n",
      "amazon bow_50 ammd 21    [0.531 0.506 0.387 0.275] ... [0.531 0.506 0.387 0.275]\n",
      "amazon bow_50 lsdd 21    [0.615 0.534 0.462 0.315] ... [0.615 0.534 0.462 0.315]\n",
      "amazon bow_50 cdbd 21    [0. 0. 0. 0.] ... [0. 0. 0. 0.]\n",
      "amazon bow_768 csdd 21    [0.9953 0.9953 0.9952 0.9952] ... [0.9953 0.9953 0.9952 0.9952]\n",
      "amazon bow_768 kts 21    [0.444  0.4538 0.3696 0.347 ] ... [0.444  0.4538 0.3696 0.347 ]\n",
      "amazon bow_768 aks 21    [0.5128 0.5121 0.5097 0.5058] ... [0.5128 0.5121 0.5097 0.5058]\n",
      "amazon bow_768 ammd 21    [0.557 0.553 0.502 0.446] ... [0.557 0.553 0.502 0.446]\n",
      "amazon bow_768 lsdd 21    [0.493 0.471 0.498 0.464] ... [0.493 0.471 0.498 0.464]\n",
      "amazon bow_768 cdbd 21    [0. 0. 0. 0.] ... [0. 0. 0. 0.]\n",
      "test testmode perfect 21    [1 0 0 0] ... [1 0 0 0]\n",
      "test testmode bad 21    [0 1 1 1] ... [0 1 1 1]\n",
      "test testmode fake 21    [0.8333 0.4    0.2    0.1333] ... [0.8333 0.4    0.2    0.1333]\n"
     ]
    }
   ],
   "source": [
    "for dataset in evaluation_data:\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            first = np.round(evaluation_data[dataset][mode][detector][:4], 4)\n",
    "            last = np.round(evaluation_data[dataset][mode][detector][0:4], 4)\n",
    "            print(dataset, mode, detector, len(evaluation_data[dataset][mode][detector]), \"  \", first, \"...\", last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric_ext(negative_words_percentage, p_values, factor_penalty, print_info):\n",
    "    \n",
    "    # remove first element (no injected drift)\n",
    "    neg_words_perc = negative_words_percentage[1:]\n",
    "    p_vals = p_values[1:]\n",
    "        \n",
    "    # Scores 0 (bad) to 1 (good)\n",
    "    scores = []\n",
    "    for i in range(len(p_vals)):\n",
    "        scores.append(1 - p_vals[i])\n",
    "    if(print_info):\n",
    "        print(\" difference score \", round(numpy.sum(scores), 4))\n",
    "    \n",
    "    # No injected drift in first element\n",
    "    # High penalty for low p-value\n",
    "    penalty = (1 - p_values[0]) * factor_penalty\n",
    "    for i in range(len(scores)):\n",
    "        scores[i] = (scores[i] - penalty)\n",
    "    if(print_info):\n",
    "        print(\" penalty \", round(penalty, 4), \"= 1 -\", round(p_values[0], 4))\n",
    "        print(round(numpy.sum(scores), 4), \"penalty score\")\n",
    "        \n",
    "    # Earlier drift detection is better (sensitivity)\n",
    "    sum_rating = 0\n",
    "    for i in range(len(scores)):\n",
    "        rating = 1/neg_words_perc[i]\n",
    "        sum_rating += rating\n",
    "        scores[i] = scores[i] * rating\n",
    "    \n",
    "    if(print_info):\n",
    "        print(\" scores \", numpy.round(scores, 2))\n",
    "        print(\" sum_rating \", round(sum_rating, 4))\n",
    "        print(\" result \", round(numpy.sum(scores) / sum_rating, 4))\n",
    "    \n",
    "    return np.sum(scores) / sum_rating\n",
    "\n",
    "\n",
    "def get_label(name):\n",
    "    mappings = {\n",
    "        \"cdbd\" : \"CDBD\",\n",
    "        \"csdd\" : \"CosSim\",\n",
    "        \"kts\" : \"KTS\",\n",
    "        \"aks\" : \"KS\",\n",
    "        \"lsdd\" : \"LSDD\",\n",
    "        \"ammd\" : \"MMD\",\n",
    "        \n",
    "        \"twitterbert_768\" : \"Twitter, BERT-768\",\n",
    "        \"twitterbow_50\" : \"Twitter, BoW-50\",\n",
    "        \"twitterbow_768\" : \"Twitter, BoW-768\",\n",
    "        \"amazonbert_768\" : \"Amazon, BERT-768\",\n",
    "        \"amazonbow_50\" : \"Amazon, BoW-50\",\n",
    "        \"amazonbow_768\" : \"Amazon, BoW-768\",\n",
    "    }\n",
    "    if(name in mappings):\n",
    "        return mappings[name]\n",
    "    else:\n",
    "        print(\"Unknown:\", name)\n",
    "        return name\n",
    "\n",
    "\n",
    "def get_sorted_detectors(detector_keys):\n",
    "    labels = {}\n",
    "    for detector in detectors:\n",
    "        labels[get_label(detector)] = detector\n",
    "    sorted_ = []\n",
    "    for detector in sorted(labels.keys()):\n",
    "        sorted_.append(labels[detector])\n",
    "    return sorted_\n",
    "\n",
    "\n",
    "def format_float(value):\n",
    "    rounded = np.round(value, 4)\n",
    "    if(rounded == 0): # handle -0.0\n",
    "        rounded = 0\n",
    "    return (format(rounded, '.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (with penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores_with_penalty = True\n",
    "\n",
    "scores = {}\n",
    "for dataset in evaluation_data:\n",
    "    scores[dataset] = {}\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        scores[dataset][mode] = {}\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            scores[dataset][mode][detector] = eval_metric_ext(negative_words_percentage, evaluation_data[dataset][mode][detector], 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon': {'bert_768': {'aks': 0.1038891377276589,\n",
      "                         'ammd': 0.35207229452446626,\n",
      "                         'cdbd': 0.0,\n",
      "                         'csdd': 0.0009419449035998787,\n",
      "                         'kts': 0.3470358487863721,\n",
      "                         'lsdd': 0.32282094194420985},\n",
      "            'bow_50': {'aks': 0.08493507904662598,\n",
      "                       'ammd': 0.30006730517979396,\n",
      "                       'cdbd': 0.0,\n",
      "                       'csdd': 0.00322754592606801,\n",
      "                       'kts': 0.3305730797663515,\n",
      "                       'lsdd': 0.35501300728480323},\n",
      "            'bow_768': {'aks': 0.031178169007641,\n",
      "                        'ammd': 0.224893615182149,\n",
      "                        'cdbd': -8.00317837646986e-11,\n",
      "                        'csdd': 0.000788754483987109,\n",
      "                        'kts': 0.20467471119561784,\n",
      "                        'lsdd': 0.09724017361297943}},\n",
      " 'test': {'testmode': {'bad': -1.0000000000000002,\n",
      "                       'fake': 0.655870437623948,\n",
      "                       'perfect': 1.0000000000000002}},\n",
      " 'twitter': {'bert_768': {'aks': 0.0681375447213533,\n",
      "                          'ammd': 0.27532391045053156,\n",
      "                          'cdbd': 0.040584582849029764,\n",
      "                          'csdd': 0.00019896378408455016,\n",
      "                          'kts': 0.27486773396261455,\n",
      "                          'lsdd': 0.28322649352588036},\n",
      "             'bow_50': {'aks': 0.1789771207290265,\n",
      "                        'ammd': 0.3084161337659523,\n",
      "                        'cdbd': -0.023975765895264758,\n",
      "                        'csdd': 0.01906157985477489,\n",
      "                        'kts': 0.268090710059177,\n",
      "                        'lsdd': 0.3342974793440688},\n",
      "             'bow_768': {'aks': 0.149306777029188,\n",
      "                         'ammd': 0.3340332000200234,\n",
      "                         'cdbd': -0.01068884085180495,\n",
      "                         'csdd': 0.058772046560898294,\n",
      "                         'kts': 0.3368189224544724,\n",
      "                         'lsdd': 0.28264320143413824}}}\n"
     ]
    }
   ],
   "source": [
    "if(print_scores_with_penalty):\n",
    "    pprint.pprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset, Model , CDBD , CosSim , KS , KTS , LSDD , MMD , $\\varnothing$ , \n",
      "Amazon, BoW-50 , 0.0000 , 0.0032 , 0.0849 , 0.3306 , 0.3550 , 0.3001 , 0.1790 , \n",
      "Amazon, BoW-768 , 0.0000 , 0.0008 , 0.0312 , 0.2047 , 0.0972 , 0.2249 , 0.0931 , \n",
      "Amazon, BERT-768 , 0.0000 , 0.0009 , 0.1039 , 0.3470 , 0.3228 , 0.3521 , 0.1878 , \n",
      "Twitter, BoW-50 , -0.0240 , 0.0191 , 0.1790 , 0.2681 , 0.3343 , 0.3084 , 0.1808 , \n",
      "Twitter, BoW-768 , -0.0107 , 0.0588 , 0.1493 , 0.3368 , 0.2826 , 0.3340 , 0.1918 , \n",
      "Twitter, BERT-768 , 0.0406 , 0.0002 , 0.0681 , 0.2749 , 0.2832 , 0.2753 , 0.1571 , \n",
      "$\\varnothing$     ,         , 0.0010 , 0.0138 , 0.1027 , 0.2937 , 0.2792 , 0.2991 , "
     ]
    }
   ],
   "source": [
    "sorted_detectors = get_sorted_detectors(scores[\"twitter\"][\"bert_768\"])\n",
    "sorted_datasets = sorted(scores.keys())\n",
    "sorted_modes = ['bow_50', 'bow_768', 'bert_768']\n",
    "\n",
    "# Get values to compute means\n",
    "s = {}\n",
    "c = {}\n",
    "sd = {}\n",
    "cd = {}\n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            sd[detector] = sd.get(detector,0) + score\n",
    "            s[dataset+mode] = s.get(dataset+mode,0) + score\n",
    "            cd[detector] = cd.get(detector,0) + 1\n",
    "            c[dataset+mode] = c.get(dataset+mode,0) + 1\n",
    "\n",
    "\n",
    "            \n",
    "end=\" , \"\n",
    "print(\"Dataset, Model\", end=end)\n",
    "for detector in sorted_detectors:\n",
    "    print(get_label(detector), end=end)\n",
    "print(\"$\\\\varnothing$\", end=end) # ∅ $\\varnothing$\n",
    "    \n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        print()\n",
    "        print(get_label(dataset+mode), end=end)\n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            print(format_float(score), end=end)\n",
    "            \n",
    "        print(format_float(s[dataset+mode]/c[dataset+mode]), end=end)\n",
    "\n",
    "print()\n",
    "print('$\\\\varnothing$     ,        ', end=end) # ∅ $\\varnothing$\n",
    "for detector in sorted_detectors:\n",
    "    print(format_float(sd[detector]/cd[detector]), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    pprint.pprint(s)\n",
    "    pprint.pprint(c)\n",
    "    pprint.pprint(sd)\n",
    "    pprint.pprint(cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (without penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores_without_penalty = True\n",
    "\n",
    "scoresNoPenalty = {}\n",
    "for dataset in evaluation_data:\n",
    "    scoresNoPenalty[dataset] = {}\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        scoresNoPenalty[dataset][mode] = {}\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            scoresNoPenalty[dataset][mode][detector] = eval_metric_ext(negative_words_percentage, evaluation_data[dataset][mode][detector], 0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon': {'bert_768': {'aks': 0.5541084112948587,\n",
      "                         'ammd': 0.6100722945244665,\n",
      "                         'cdbd': 1.0000000000000002,\n",
      "                         'csdd': 0.001617742366063258,\n",
      "                         'kts': 0.6262358487863721,\n",
      "                         'lsdd': 0.6018209709120674},\n",
      "            'bow_50': {'aks': 0.5691815118278455,\n",
      "                       'ammd': 0.7690673051797943,\n",
      "                       'cdbd': 1.0000000000000002,\n",
      "                       'csdd': 0.005845381924603167,\n",
      "                       'kts': 0.7507730797663515,\n",
      "                       'lsdd': 0.7400130260602666},\n",
      "            'bow_768': {'aks': 0.5183443949178279,\n",
      "                        'ammd': 0.6678936151821491,\n",
      "                        'cdbd': 0.9999999999115522,\n",
      "                        'csdd': 0.005456990262795705,\n",
      "                        'kts': 0.7606747111956179,\n",
      "                        'lsdd': 0.6042401833285367}},\n",
      " 'test': {'testmode': {'bad': 0.0,\n",
      "                       'fake': 0.8225371042906146,\n",
      "                       'perfect': 1.0000000000000002}},\n",
      " 'twitter': {'bert_768': {'aks': 0.5503075304925326,\n",
      "                          'ammd': 0.7283239104505317,\n",
      "                          'cdbd': 0.7995226357138224,\n",
      "                          'csdd': 0.00042850127111457954,\n",
      "                          'kts': 0.6838677339626147,\n",
      "                          'lsdd': 0.7112265055660189},\n",
      "             'bow_50': {'aks': 0.6858343370872114,\n",
      "                        'ammd': 0.9254161337659524,\n",
      "                        'cdbd': 0.7731019127593601,\n",
      "                        'csdd': 0.023990049512672838,\n",
      "                        'kts': 0.9256907100591771,\n",
      "                        'lsdd': 0.8912974922261228},\n",
      "             'bow_768': {'aks': 0.6507179169942454,\n",
      "                         'ammd': 0.8980332000200234,\n",
      "                         'cdbd': 0.7042950068135075,\n",
      "                         'csdd': 0.1351430606790929,\n",
      "                         'kts': 0.8718189224544726,\n",
      "                         'lsdd': 0.852643212721768}}}\n"
     ]
    }
   ],
   "source": [
    "if(print_scores_without_penalty):\n",
    "    pprint.pprint(scoresNoPenalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset, Model , CDBD , CosSim , KS , KTS , LSDD , MMD , $\\varnothing$ , \n",
      "Amazon, BoW-50 , 1.0000 , 0.0058 , 0.5692 , 0.7508 , 0.7400 , 0.7691 , 0.6391 , \n",
      "Amazon, BoW-768 , 1.0000 , 0.0055 , 0.5183 , 0.7607 , 0.6042 , 0.6679 , 0.5928 , \n",
      "Amazon, BERT-768 , 1.0000 , 0.0016 , 0.5541 , 0.6262 , 0.6018 , 0.6101 , 0.5656 , \n",
      "Twitter, BoW-50 , 0.7731 , 0.0240 , 0.6858 , 0.9257 , 0.8913 , 0.9254 , 0.7042 , \n",
      "Twitter, BoW-768 , 0.7043 , 0.1351 , 0.6507 , 0.8718 , 0.8526 , 0.8980 , 0.6854 , \n",
      "Twitter, BERT-768 , 0.7995 , 0.0004 , 0.5503 , 0.6839 , 0.7112 , 0.7283 , 0.5789 , \n",
      "$\\varnothing$     ,         , 0.8795 , 0.0287 , 0.5881 , 0.7698 , 0.7335 , 0.7665 , "
     ]
    }
   ],
   "source": [
    "sorted_detectors = get_sorted_detectors(scores[\"twitter\"][\"bert_768\"])\n",
    "sorted_datasets = sorted(scores.keys())\n",
    "sorted_modes = ['bow_50', 'bow_768', 'bert_768']\n",
    "\n",
    "# Get values to compute means\n",
    "s = {}\n",
    "c = {}\n",
    "sd = {}\n",
    "cd = {}\n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        for detector in sorted_detectors:\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            sd[detector] = sd.get(detector,0) + score\n",
    "            s[dataset+mode] = s.get(dataset+mode,0) + score\n",
    "            cd[detector] = cd.get(detector,0) + 1\n",
    "            c[dataset+mode] = c.get(dataset+mode,0) + 1\n",
    "\n",
    "\n",
    "            \n",
    "end=\" , \"\n",
    "print(\"Dataset, Model\", end=end)\n",
    "for detector in sorted_detectors:\n",
    "    print(get_label(detector), end=end)\n",
    "print(\"$\\\\varnothing$\", end=end) # ∅ $\\varnothing$\n",
    "    \n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        print()\n",
    "        print(get_label(dataset+mode), end=end)\n",
    "        for detector in sorted_detectors:\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            print(format_float(score), end=end)\n",
    "            \n",
    "        print(format_float(s[dataset+mode]/c[dataset+mode]), end=end)\n",
    "\n",
    "print()\n",
    "print('$\\\\varnothing$     ,        ', end=end) # ∅ $\\varnothing$\n",
    "for detector in sorted_detectors:\n",
    "    print(format_float(sd[detector]/cd[detector]), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    pprint.pprint(s)\n",
    "    pprint.pprint(c)\n",
    "    pprint.pprint(sd)\n",
    "    pprint.pprint(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EML4U)",
   "language": "python",
   "name": "eml4u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

