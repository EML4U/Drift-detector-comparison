{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores of injection experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = \"../data/results/\"\n",
    "evaluation_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter_diff_dist   ../data/results/twitter_diff_dist.pickle   <class 'tuple'>   3\n",
      "twitter_drift_induction   ../data/results/twitter_drift_induction.pickle   <class 'dict'>   3\n",
      "amazon_diff_classes   ../data/results/amazon_diff_classes.pickle   <class 'dict'>   3\n",
      "amazon_same_dist   ../data/results/amazon_same_dist.pickle   <class 'dict'>   3\n",
      "twitter_same_dist   ../data/results/twitter_same_dist.pickle   <class 'dict'>   3\n",
      "twitter_diff_classes   ../data/results/twitter_diff_classes.pickle   <class 'dict'>   3\n",
      "amazon_drift_induction   ../data/results/amazon_drift_induction.pickle   <class 'dict'>   3\n"
     ]
    }
   ],
   "source": [
    "results_meta = {}\n",
    "\n",
    "# get files and ids\n",
    "for name in listdir(results_directory):\n",
    "    path = join(results_directory, name)\n",
    "    if isfile(path):\n",
    "        id = name[:-7]\n",
    "        results_meta[id] = {\"result_pickle\":path}\n",
    "\n",
    "# add data\n",
    "for key in results_meta:\n",
    "    with open(results_meta[key][\"result_pickle\"], 'rb') as handle:\n",
    "        results_meta[key][\"data\"] = pickle.load(handle)\n",
    "\n",
    "# print info\n",
    "for key in results_meta: \n",
    "    print(\n",
    "        key, \" \",\n",
    "        results_meta[key][\"result_pickle\"], \" \",\n",
    "        type(results_meta[key][\"data\"]), \" \",\n",
    "        len(results_meta[key][\"data\"])\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results: twitter_drift_induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config from notebook\n",
    "permutations = 10\n",
    "modes = ['bert_768', 'bow_50', 'bow_768']\n",
    "target_percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "detectors = {\n",
    "    'csdd': 'CosineSimilarityDriftDetector()',\n",
    "    'kts' : 'KernelTwoSampleDriftDetector()',\n",
    "    'aks' : 'AlibiKSDetector()',\n",
    "    'ammd': 'AlibiMMDDetector()',\n",
    "    'lsdd': 'AlibiLSDDDetector()',\n",
    "    'cdbd': 'CDBDDetector()',\n",
    "}\n",
    "result_pickle = results_meta[\"twitter_drift_induction\"][\"result_pickle\"]\n",
    "try:\n",
    "    del results\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading result pickle:  ../data/results/twitter_drift_induction.pickle\n",
      "bert_768\n",
      "bow_50\n",
      "bow_768\n"
     ]
    }
   ],
   "source": [
    "evaluation_data[\"twitter\"] = {}\n",
    "\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    print('Loading result pickle: ', result_pickle)\n",
    "    with open(result_pickle, 'rb') as handle:\n",
    "        results = pickle.load(handle)    \n",
    "\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    plot_data = {}\n",
    "       \n",
    "    for detector in detectors:\n",
    "        plot_data[detector] = []\n",
    "        for n in range(len(results[mode][detector]['predictions'][0])):\n",
    "            nth_entries = [results[mode][detector]['predictions'][i][n] for i in range(permutations)]\n",
    "            plot_data[detector].append(np.mean(nth_entries))\n",
    "\n",
    "    evaluation_data[\"twitter\"][mode] = plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results: amazon_drift_induction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config from notebook\n",
    "permutations = 10\n",
    "modes = ['bert_768', 'bow_50', 'bow_768']\n",
    "target_percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "detectors = {\n",
    "    'csdd': \"\",\n",
    "    'kts' : \"\",\n",
    "    'aks' : \"\",\n",
    "    'ammd': \"\",\n",
    "    'lsdd': \"\",\n",
    "    'cdbd': \"\",\n",
    "}\n",
    "result_pickle = results_meta[\"amazon_drift_induction\"][\"result_pickle\"]\n",
    "try:\n",
    "    del results\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading result pickle:  ../data/results/amazon_drift_induction.pickle\n",
      "bert_768\n",
      "bow_50\n",
      "bow_768\n"
     ]
    }
   ],
   "source": [
    "evaluation_data[\"amazon\"] = {}\n",
    "\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    print('Loading result pickle: ', result_pickle)\n",
    "    with open(result_pickle, 'rb') as handle:\n",
    "        results = pickle.load(handle)    \n",
    "\n",
    "# plot\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    plot_data = {}\n",
    "       \n",
    "    for detector in detectors:\n",
    "        plot_data[detector] = []\n",
    "        for n in range(len(results[mode][detector]['predictions'][0])):\n",
    "            nth_entries = [results[mode][detector]['predictions'][i][n] for i in range(permutations)]\n",
    "            plot_data[detector].append(np.mean(nth_entries))\n",
    "            \n",
    "    evaluation_data[\"amazon\"][mode] = plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of conducted experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_words_percentage [0.    0.025 0.05  0.075 0.1   0.125 0.15  0.175 0.2   0.225 0.25  0.275\n",
      " 0.3   0.325 0.35  0.375 0.4   0.425 0.45  0.475 0.5  ]\n"
     ]
    }
   ],
   "source": [
    "target_percentages = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "negative_words_percentage = np.divide(target_percentages, 2)\n",
    "print(\"negative_words_percentage\", negative_words_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add comparison detector values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data['test'] = {}\n",
    "evaluation_data['test']['testmode'] = {}\n",
    "\n",
    "fake_predictions = [0] * 21\n",
    "fake_predictions[0] = 1\n",
    "evaluation_data['test']['testmode']['perfect'] = fake_predictions\n",
    "\n",
    "fake_predictions = [1] * 21\n",
    "fake_predictions[0] = 0\n",
    "evaluation_data['test']['testmode']['bad'] = fake_predictions\n",
    "\n",
    "fake_predictions = negative_words_percentage\n",
    "fake_predictions[0] = .012\n",
    "fake_predictions = np.divide(.01, fake_predictions)\n",
    "evaluation_data['test']['testmode']['fake'] = fake_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter bert_768 csdd 21    [0.9998 0.9998 0.9998 0.9997] ... [0.9998 0.9998 0.9998 0.9997]\n",
      "twitter bert_768 kts 21    [0.591  0.5846 0.538  0.4364] ... [0.591  0.5846 0.538  0.4364]\n",
      "twitter bert_768 aks 21    [0.5178 0.5154 0.5094 0.5009] ... [0.5178 0.5154 0.5094 0.5009]\n",
      "twitter bert_768 ammd 21    [0.547 0.532 0.453 0.347] ... [0.547 0.532 0.453 0.347]\n",
      "twitter bert_768 lsdd 21    [0.572 0.518 0.47  0.374] ... [0.572 0.518 0.47  0.374]\n",
      "twitter bert_768 cdbd 21    [0.8219 0.8201 0.8238 0.7922] ... [0.8219 0.8201 0.8238 0.7922]\n",
      "twitter bow_50 csdd 21    [0.9951 0.9945 0.9934 0.9918] ... [0.9951 0.9945 0.9934 0.9918]\n",
      "twitter bow_50 kts 21    [0.3424 0.2188 0.0786 0.0164] ... [0.3424 0.2188 0.0786 0.0164]\n",
      "twitter bow_50 aks 21    [0.4931 0.4776 0.4279 0.3877] ... [0.4931 0.4776 0.4279 0.3877]\n",
      "twitter bow_50 ammd 21    [0.383 0.22  0.087 0.013] ... [0.383 0.22  0.087 0.013]\n",
      "twitter bow_50 lsdd 21    [0.443 0.294 0.141 0.049] ... [0.443 0.294 0.141 0.049]\n",
      "twitter bow_50 cdbd 21    [0.5944 0.5932 0.596  0.6696] ... [0.5944 0.5932 0.596  0.6696]\n",
      "twitter bow_768 csdd 21    [0.9236 0.9235 0.9216 0.9161] ... [0.9236 0.9235 0.9216 0.9161]\n",
      "twitter bow_768 kts 21    [0.465  0.3772 0.1494 0.0172] ... [0.465  0.3772 0.1494 0.0172]\n",
      "twitter bow_768 aks 21    [0.4986 0.4889 0.4653 0.4328] ... [0.4986 0.4889 0.4653 0.4328]\n",
      "twitter bow_768 ammd 21    [0.436 0.281 0.123 0.054] ... [0.436 0.281 0.123 0.054]\n",
      "twitter bow_768 lsdd 21    [0.43  0.287 0.212 0.171] ... [0.43  0.287 0.212 0.171]\n",
      "twitter bow_768 cdbd 21    [0.3338 0.3163 0.2595 0.2218] ... [0.3338 0.3163 0.2595 0.2218]\n",
      "amazon bert_768 csdd 21    [0.9993 0.9993 0.9992 0.9991] ... [0.9993 0.9993 0.9992 0.9991]\n",
      "amazon bert_768 kts 21    [0.7208 0.6936 0.6286 0.5108] ... [0.7208 0.6936 0.6286 0.5108]\n",
      "amazon bert_768 aks 21    [0.5498 0.5437 0.5309 0.5109] ... [0.5498 0.5437 0.5309 0.5109]\n",
      "amazon bert_768 ammd 21    [0.742 0.736 0.643 0.523] ... [0.742 0.736 0.643 0.523]\n",
      "amazon bert_768 lsdd 21    [0.721 0.703 0.647 0.546] ... [0.721 0.703 0.647 0.546]\n",
      "amazon bert_768 cdbd 21    [0.8253 0.8172 0.8054 0.804 ] ... [0.8253 0.8172 0.8054 0.804 ]\n",
      "amazon bow_50 csdd 21    [0.9974 0.9973 0.9971 0.9968] ... [0.9974 0.9973 0.9971 0.9968]\n",
      "amazon bow_50 kts 21    [0.5798 0.5368 0.427  0.2852] ... [0.5798 0.5368 0.427  0.2852]\n",
      "amazon bow_50 aks 21    [0.5158 0.5121 0.5065 0.4979] ... [0.5158 0.5121 0.5065 0.4979]\n",
      "amazon bow_50 ammd 21    [0.531 0.506 0.387 0.275] ... [0.531 0.506 0.387 0.275]\n",
      "amazon bow_50 lsdd 21    [0.615 0.534 0.462 0.315] ... [0.615 0.534 0.462 0.315]\n",
      "amazon bow_50 cdbd 21    [0.5781 0.4287 0.4976 0.4896] ... [0.5781 0.4287 0.4976 0.4896]\n",
      "amazon bow_768 csdd 21    [0.9953 0.9953 0.9952 0.9952] ... [0.9953 0.9953 0.9952 0.9952]\n",
      "amazon bow_768 kts 21    [0.444  0.4538 0.3696 0.347 ] ... [0.444  0.4538 0.3696 0.347 ]\n",
      "amazon bow_768 aks 21    [0.5128 0.5121 0.5097 0.5058] ... [0.5128 0.5121 0.5097 0.5058]\n",
      "amazon bow_768 ammd 21    [0.557 0.553 0.502 0.446] ... [0.557 0.553 0.502 0.446]\n",
      "amazon bow_768 lsdd 21    [0.493 0.471 0.498 0.464] ... [0.493 0.471 0.498 0.464]\n",
      "amazon bow_768 cdbd 21    [0.4283 0.3491 0.4576 0.426 ] ... [0.4283 0.3491 0.4576 0.426 ]\n",
      "test testmode perfect 21    [1 0 0 0] ... [1 0 0 0]\n",
      "test testmode bad 21    [0 1 1 1] ... [0 1 1 1]\n",
      "test testmode fake 21    [0.8333 0.4    0.2    0.1333] ... [0.8333 0.4    0.2    0.1333]\n"
     ]
    }
   ],
   "source": [
    "for dataset in evaluation_data:\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            first = np.round(evaluation_data[dataset][mode][detector][:4], 4)\n",
    "            last = np.round(evaluation_data[dataset][mode][detector][0:4], 4)\n",
    "            print(dataset, mode, detector, len(evaluation_data[dataset][mode][detector]), \"  \", first, \"...\", last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric_ext(negative_words_percentage, p_values, factor_penalty, print_info):\n",
    "    \n",
    "    # remove first element (no injected drift)\n",
    "    neg_words_perc = negative_words_percentage[1:]\n",
    "    p_vals = p_values[1:]\n",
    "        \n",
    "    # Scores 0 (bad) to 1 (good)\n",
    "    scores = []\n",
    "    for i in range(len(p_vals)):\n",
    "        scores.append(1 - p_vals[i])\n",
    "    if(print_info):\n",
    "        print(\" difference score \", round(numpy.sum(scores), 4))\n",
    "    \n",
    "    # No injected drift in first element\n",
    "    # High penalty for low p-value\n",
    "    penalty = (1 - p_values[0]) * factor_penalty\n",
    "    for i in range(len(scores)):\n",
    "        scores[i] = (scores[i] - penalty)\n",
    "    if(print_info):\n",
    "        print(\" penalty \", round(penalty, 4), \"= 1 -\", round(p_values[0], 4))\n",
    "        print(round(numpy.sum(scores), 4), \"penalty score\")\n",
    "        \n",
    "    # Earlier drift detection is better (sensitivity)\n",
    "    sum_rating = 0\n",
    "    for i in range(len(scores)):\n",
    "        rating = 1/neg_words_perc[i]\n",
    "        sum_rating += rating\n",
    "        scores[i] = scores[i] * rating\n",
    "    \n",
    "    if(print_info):\n",
    "        print(\" scores \", numpy.round(scores, 2))\n",
    "        print(\" sum_rating \", round(sum_rating, 4))\n",
    "        print(\" result \", round(numpy.sum(scores) / sum_rating, 4))\n",
    "    \n",
    "    return np.sum(scores) / sum_rating\n",
    "\n",
    "\n",
    "def get_label(name):\n",
    "    mappings = {\n",
    "        \"cdbd\" : \"CDBD\",\n",
    "        \"csdd\" : \"CosSim\",\n",
    "        \"kts\" : \"KTS/MMD\",\n",
    "        \"aks\" : \"KS\",\n",
    "        \"lsdd\" : \"LSDD\",\n",
    "        \"ammd\" : \"MMD\",\n",
    "        \n",
    "        \"twitterbert_768\" : \"Twitter, BERT-768\",\n",
    "        \"twitterbow_50\"   : \"Twitter, BoW-50  \",\n",
    "        \"twitterbow_768\"  : \"Twitter, BoW-768 \",\n",
    "        \"amazonbert_768\"  : \"Amazon,  BERT-768\",\n",
    "        \"amazonbow_50\"    : \"Amazon,  BoW-50  \",\n",
    "        \"amazonbow_768\"   : \"Amazon,  BoW-768 \",\n",
    "    }\n",
    "    if(name in mappings):\n",
    "        return mappings[name]\n",
    "    else:\n",
    "        print(\"Unknown:\", name)\n",
    "        return name\n",
    "\n",
    "\n",
    "def get_sorted_detectors(detector_keys):\n",
    "    labels = {}\n",
    "    for detector in detectors:\n",
    "        labels[get_label(detector)] = detector\n",
    "    sorted_ = []\n",
    "    for detector in sorted(labels.keys()):\n",
    "        sorted_.append(labels[detector])\n",
    "    return sorted_\n",
    "\n",
    "\n",
    "def format_float(value):\n",
    "    rounded = np.round(value, 4)\n",
    "    if(rounded == 0): # handle -0.0\n",
    "        rounded = 0\n",
    "    return (format(rounded, '.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximim index for evaluation: 20 which is percentage 0.5\n"
     ]
    }
   ],
   "source": [
    "max_index = 20 # 20: all, 12: to 0.3\n",
    "print(\"Maximim index for evaluation:\", max_index, \"which is percentage\", negative_words_percentage[max_index])\n",
    "\n",
    "print_textbf = True\n",
    "#best_marker_start = \"\\\\textbf{\" \n",
    "#best_marker_start = \"BSLSHBSLSHtextbf{\" # backslashes could not be parsed in online tool\n",
    "#best_marker_end = \"}\"\n",
    "best_marker_start = \"\"\n",
    "best_marker_end = \"⬛\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (with penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores_with_penalty = True\n",
    "alpha = 1\n",
    "\n",
    "scores = {}\n",
    "for dataset in evaluation_data:\n",
    "    scores[dataset] = {}\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        scores[dataset][mode] = {}\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            scores[dataset][mode][detector] = eval_metric_ext(negative_words_percentage[:max_index], evaluation_data[dataset][mode][detector][:max_index], alpha, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon': {'bert_768': {'aks': 0.10018429189047545,\n",
      "                         'ammd': 0.34657685597543997,\n",
      "                         'cdbd': 0.0705508117628693,\n",
      "                         'csdd': 0.0008739953374681871,\n",
      "                         'kts': 0.34179639793680017,\n",
      "                         'lsdd': 0.3172092135260019},\n",
      "            'bow_50': {'aks': 0.08151503231844369,\n",
      "                       'ammd': 0.29681265972751,\n",
      "                       'cdbd': 0.20156011591095302,\n",
      "                       'csdd': 0.002978010641077654,\n",
      "                       'kts': 0.32708879196445717,\n",
      "                       'lsdd': 0.3513488859136617},\n",
      "            'bow_768': {'aks': 0.029287486922476864,\n",
      "                        'ammd': 0.2202271737741508,\n",
      "                        'cdbd': 0.0977993823393399,\n",
      "                        'csdd': 0.0007262213844526468,\n",
      "                        'kts': 0.2013299718440915,\n",
      "                        'lsdd': 0.09291686007044979}},\n",
      " 'test': {'testmode': {'bad': -1.0000000000000002,\n",
      "                       'fake': 0.6536512373594596,\n",
      "                       'perfect': 1.0000000000000002}},\n",
      " 'twitter': {'bert_768': {'aks': 0.06478193482021283,\n",
      "                          'ammd': 0.2714950487554178,\n",
      "                          'cdbd': 0.07273538930171188,\n",
      "                          'csdd': 0.00018301825261039066,\n",
      "                          'kts': 0.2704405169681988,\n",
      "                          'lsdd': 0.27915666988686966},\n",
      "             'bow_50': {'aks': 0.17503302823156983,\n",
      "                        'ammd': 0.30736498749477836,\n",
      "                        'cdbd': 0.014548368089689057,\n",
      "                        'csdd': 0.017480830533437623,\n",
      "                        'kts': 0.2670716204848445,\n",
      "                        'lsdd': 0.3327654826605608},\n",
      "             'bow_768': {'aks': 0.14477792301700526,\n",
      "                         'ammd': 0.3325961329035756,\n",
      "                         'cdbd': 0.1236430030133646,\n",
      "                         'csdd': 0.05424737873312453,\n",
      "                         'kts': 0.33504059188712865,\n",
      "                         'lsdd': 0.2805664314126752}}}\n"
     ]
    }
   ],
   "source": [
    "if(print_scores_with_penalty):\n",
    "    pprint.pprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 1\n",
      "max_index 20\n",
      "Dataset, Model    , CDBD , KS , KTS/MMD , LSDD , $\\varnothing$ , \n",
      "Amazon,  BoW-50   , 0.2016 , 0.0815 , 0.3271 , 0.3513⬛ , 0.2404 , \n",
      "Amazon,  BoW-768  , 0.0978 , 0.0293 , 0.2013⬛ , 0.0929 , 0.1053 , \n",
      "Amazon,  BERT-768 , 0.0706 , 0.1002 , 0.3418⬛ , 0.3172 , 0.2074 , \n",
      "Twitter, BoW-50   , 0.0145 , 0.1750 , 0.2671 , 0.3328⬛ , 0.1974 , \n",
      "Twitter, BoW-768  , 0.1236 , 0.1448 , 0.3350⬛ , 0.2806 , 0.2210 , \n",
      "Twitter, BERT-768 , 0.0727 , 0.0648 , 0.2704 , 0.2792⬛ , 0.1718 , \n",
      "$\\varnothing$     ,        , 0.0968 , 0.0993 , 0.2905 , 0.2757 , "
     ]
    }
   ],
   "source": [
    "sorted_detectors = get_sorted_detectors(scores[\"twitter\"][\"bert_768\"])\n",
    "sorted_detectors.remove(\"csdd\") # Remove CosSim\n",
    "sorted_detectors.remove(\"ammd\") # Remove MMD\n",
    "sorted_datasets = sorted(scores.keys())\n",
    "sorted_modes = ['bow_50', 'bow_768', 'bert_768']\n",
    "\n",
    "print(\"alpha\", alpha)\n",
    "print(\"max_index\", max_index)\n",
    "\n",
    "# Get values to compute means\n",
    "s = {}\n",
    "c = {}\n",
    "sd = {}\n",
    "cd = {}\n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            sd[detector] = sd.get(detector,0) + score\n",
    "            cd[detector] = cd.get(detector,0) + 1\n",
    "            #if(detector == \"cdbd\" or detector == \"csdd\"): # Exclude detectors from mode mean\n",
    "            #    print(\"Skipping\", detector, \"for mode mean\")\n",
    "            #    continue\n",
    "            s[dataset+mode] = s.get(dataset+mode,0) + score\n",
    "            c[dataset+mode] = c.get(dataset+mode,0) + 1\n",
    "\n",
    "\n",
    "            \n",
    "end=\" , \"\n",
    "print(\"Dataset, Model   \", end=end)\n",
    "for detector in sorted_detectors:\n",
    "    print(get_label(detector), end=end)\n",
    "print(\"$\\\\varnothing$\", end=end) # ∅ $\\varnothing$\n",
    "    \n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        print()\n",
    "        print(get_label(dataset+mode), end=end)\n",
    "        \n",
    "        max_detector = None\n",
    "        max_score = -2\n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            if(score > max_score):\n",
    "                max_score = score\n",
    "                max_detector = detector\n",
    "                \n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_start, end=\"\")\n",
    "            print(format_float(score), end=\"\")\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_end, end=\"\")\n",
    "            print(\"\", end=end)\n",
    "            \n",
    "        print(format_float(s[dataset+mode]/c[dataset+mode]), end=end)\n",
    "\n",
    "print()\n",
    "print('$\\\\varnothing$     ,       ', end=end) # ∅ $\\varnothing$\n",
    "for detector in sorted_detectors:\n",
    "    print(format_float(sd[detector]/cd[detector]), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    pprint.pprint(s)\n",
    "    pprint.pprint(c)\n",
    "    pprint.pprint(sd)\n",
    "    pprint.pprint(cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (without penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores_without_penalty = True\n",
    "alpha = 0\n",
    "\n",
    "scoresNoPenalty = {}\n",
    "for dataset in evaluation_data:\n",
    "    scoresNoPenalty[dataset] = {}\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        scoresNoPenalty[dataset][mode] = {}\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            scoresNoPenalty[dataset][mode][detector] = eval_metric_ext(negative_words_percentage[:max_index], evaluation_data[dataset][mode][detector][:max_index], alpha, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon': {'bert_768': {'aks': 0.5504035654576752,\n",
      "                         'ammd': 0.6045768559754402,\n",
      "                         'cdbd': 0.24527233704484538,\n",
      "                         'csdd': 0.0015497927999315662,\n",
      "                         'kts': 0.6209963979368003,\n",
      "                         'lsdd': 0.5962092424938594},\n",
      "            'bow_50': {'aks': 0.5657614650996633,\n",
      "                       'ammd': 0.7658126597275102,\n",
      "                       'cdbd': 0.623461477899139,\n",
      "                       'csdd': 0.005595846639612811,\n",
      "                       'kts': 0.7472887919644573,\n",
      "                       'lsdd': 0.7363489046891251},\n",
      "            'bow_768': {'aks': 0.5164537128326637,\n",
      "                        'ammd': 0.6632271737741509,\n",
      "                        'cdbd': 0.6694941971503965,\n",
      "                        'csdd': 0.005394457163261242,\n",
      "                        'kts': 0.7573299718440916,\n",
      "                        'lsdd': 0.5999168697860071}},\n",
      " 'test': {'testmode': {'bad': 0.0,\n",
      "                       'fake': 0.8203179040261263,\n",
      "                       'perfect': 1.0000000000000002}},\n",
      " 'twitter': {'bert_768': {'aks': 0.5469519205913921,\n",
      "                          'ammd': 0.724495048755418,\n",
      "                          'cdbd': 0.25080563036119774,\n",
      "                          'csdd': 0.00041255573964042003,\n",
      "                          'kts': 0.679440516968199,\n",
      "                          'lsdd': 0.7071566819270081},\n",
      "             'bow_50': {'aks': 0.6818902445897548,\n",
      "                        'ammd': 0.9243649874947786,\n",
      "                        'cdbd': 0.420152197639358,\n",
      "                        'csdd': 0.02240930019133557,\n",
      "                        'kts': 0.9246716204848445,\n",
      "                        'lsdd': 0.8897654955426147},\n",
      "             'bow_768': {'aks': 0.6461890629820627,\n",
      "                         'ammd': 0.8965961329035758,\n",
      "                         'cdbd': 0.7898128188854431,\n",
      "                         'csdd': 0.13061839285131913,\n",
      "                         'kts': 0.8700405918871288,\n",
      "                         'lsdd': 0.850566442700305}}}\n"
     ]
    }
   ],
   "source": [
    "if(print_scores_without_penalty):\n",
    "    pprint.pprint(scoresNoPenalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0\n",
      "max_index 20\n",
      "Dataset, Model    , CDBD , KS , KTS/MMD , LSDD , $\\varnothing$ , \n",
      "Amazon,  BoW-50   , 0.6235 , 0.5658 , 0.7473⬛ , 0.7363 , 0.6682 , \n",
      "Amazon,  BoW-768  , 0.6695 , 0.5165 , 0.7573⬛ , 0.5999 , 0.6358 , \n",
      "Amazon,  BERT-768 , 0.2453 , 0.5504 , 0.6210⬛ , 0.5962 , 0.5032 , \n",
      "Twitter, BoW-50   , 0.4202 , 0.6819 , 0.9247⬛ , 0.8898 , 0.7291 , \n",
      "Twitter, BoW-768  , 0.7898 , 0.6462 , 0.8700⬛ , 0.8506 , 0.7892 , \n",
      "Twitter, BERT-768 , 0.2508 , 0.5470 , 0.6794 , 0.7072⬛ , 0.5461 , \n",
      "$\\varnothing$     ,        , 0.4998 , 0.5846 , 0.7666 , 0.7300 , "
     ]
    }
   ],
   "source": [
    "sorted_detectors = get_sorted_detectors(scores[\"twitter\"][\"bert_768\"])\n",
    "sorted_detectors.remove(\"csdd\") # Remove CosSim\n",
    "sorted_detectors.remove(\"ammd\") # Remove MMD\n",
    "sorted_datasets = sorted(scores.keys())\n",
    "sorted_modes = ['bow_50', 'bow_768', 'bert_768']\n",
    "\n",
    "print(\"alpha\", alpha)\n",
    "print(\"max_index\", max_index)\n",
    "\n",
    "# Get values to compute means\n",
    "s = {}\n",
    "c = {}\n",
    "sd = {}\n",
    "cd = {}\n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        for detector in sorted_detectors:\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            sd[detector] = sd.get(detector,0) + score\n",
    "            cd[detector] = cd.get(detector,0) + 1\n",
    "            #if(detector == \"cdbd\" or detector == \"csdd\"): # Exclude detectors from mode mean\n",
    "            #    print(\"Skipping\", detector, \"for mode mean\")\n",
    "            #    continue\n",
    "            c[dataset+mode] = c.get(dataset+mode,0) + 1\n",
    "            s[dataset+mode] = s.get(dataset+mode,0) + score\n",
    "\n",
    "\n",
    "            \n",
    "end=\" , \"\n",
    "print(\"Dataset, Model   \", end=end)\n",
    "for detector in sorted_detectors:\n",
    "    print(get_label(detector), end=end)\n",
    "print(\"$\\\\varnothing$\", end=end) # ∅ $\\varnothing$\n",
    "    \n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        print()\n",
    "        print(get_label(dataset+mode), end=end)\n",
    "        \n",
    "        max_detector = None\n",
    "        max_score = -2\n",
    "        for detector in sorted_detectors:\n",
    "            #if(detector == \"cdbd\"): # exclude from max scores\n",
    "            #    continue\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            if(score > max_score):\n",
    "                max_score = score\n",
    "                max_detector = detector\n",
    "\n",
    "        for detector in sorted_detectors:\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_start, end=\"\")\n",
    "            print(format_float(score), end=\"\")\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_end, end=\"\")\n",
    "            print(\"\", end=end)\n",
    "            \n",
    "        print(format_float(s[dataset+mode]/c[dataset+mode]), end=end)\n",
    "\n",
    "print()\n",
    "print('$\\\\varnothing$     ,       ', end=end) # ∅ $\\varnothing$\n",
    "for detector in sorted_detectors:\n",
    "    print(format_float(sd[detector]/cd[detector]), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    pprint.pprint(s)\n",
    "    pprint.pprint(c)\n",
    "    pprint.pprint(sd)\n",
    "    pprint.pprint(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project)",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

