{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores of injection experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = \"../data/results/\"\n",
    "evaluation_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter_diff_dist   ../data/results/twitter_diff_dist.pickle   <class 'tuple'>   3\n",
      "twitter_drift_induction   ../data/results/twitter_drift_induction.pickle   <class 'dict'>   3\n",
      "amazon_diff_classes   ../data/results/amazon_diff_classes.pickle   <class 'dict'>   3\n",
      "amazon_same_dist   ../data/results/amazon_same_dist.pickle   <class 'dict'>   3\n",
      "twitter_same_dist   ../data/results/twitter_same_dist.pickle   <class 'dict'>   3\n",
      "twitter_diff_classes   ../data/results/twitter_diff_classes.pickle   <class 'dict'>   3\n",
      "amazon_drift_induction   ../data/results/amazon_drift_induction.pickle   <class 'dict'>   3\n"
     ]
    }
   ],
   "source": [
    "results_meta = {}\n",
    "\n",
    "# get files and ids\n",
    "for name in listdir(results_directory):\n",
    "    path = join(results_directory, name)\n",
    "    if isfile(path):\n",
    "        id = name[:-7]\n",
    "        results_meta[id] = {\"result_pickle\":path}\n",
    "\n",
    "# add data\n",
    "for key in results_meta:\n",
    "    with open(results_meta[key][\"result_pickle\"], 'rb') as handle:\n",
    "        results_meta[key][\"data\"] = pickle.load(handle)\n",
    "\n",
    "# print info\n",
    "for key in results_meta: \n",
    "    print(\n",
    "        key, \" \",\n",
    "        results_meta[key][\"result_pickle\"], \" \",\n",
    "        type(results_meta[key][\"data\"]), \" \",\n",
    "        len(results_meta[key][\"data\"])\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results: twitter_drift_induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config from notebook\n",
    "permutations = 10\n",
    "modes = ['bert_768', 'bow_50', 'bow_768']\n",
    "target_percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "detectors = {\n",
    "    'csdd': 'CosineSimilarityDriftDetector()',\n",
    "    'kts' : 'KernelTwoSampleDriftDetector()',\n",
    "    'aks' : 'AlibiKSDetector()',\n",
    "    'ammd': 'AlibiMMDDetector()',\n",
    "    'lsdd': 'AlibiLSDDDetector()',\n",
    "    'cdbd': 'CDBDDetector()',\n",
    "}\n",
    "result_pickle = results_meta[\"twitter_drift_induction\"][\"result_pickle\"]\n",
    "try:\n",
    "    del results\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading result pickle:  ../data/results/twitter_drift_induction.pickle\n",
      "bert_768\n",
      "bow_50\n",
      "bow_768\n"
     ]
    }
   ],
   "source": [
    "evaluation_data[\"twitter\"] = {}\n",
    "\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    print('Loading result pickle: ', result_pickle)\n",
    "    with open(result_pickle, 'rb') as handle:\n",
    "        results = pickle.load(handle)    \n",
    "\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    plot_data = {}\n",
    "       \n",
    "    for detector in detectors:\n",
    "        plot_data[detector] = []\n",
    "        for n in range(len(results[mode][detector]['predictions'][0])):\n",
    "            nth_entries = [results[mode][detector]['predictions'][i][n] for i in range(permutations)]\n",
    "            plot_data[detector].append(np.mean(nth_entries))\n",
    "\n",
    "    evaluation_data[\"twitter\"][mode] = plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results: amazon_drift_induction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config from notebook\n",
    "permutations = 10\n",
    "modes = ['bert_768', 'bow_50', 'bow_768']\n",
    "target_percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "detectors = {\n",
    "    'csdd': \"\",\n",
    "    'kts' : \"\",\n",
    "    'aks' : \"\",\n",
    "    'ammd': \"\",\n",
    "    'lsdd': \"\",\n",
    "    'cdbd': \"\",\n",
    "}\n",
    "result_pickle = results_meta[\"amazon_drift_induction\"][\"result_pickle\"]\n",
    "try:\n",
    "    del results\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading result pickle:  ../data/results/amazon_drift_induction.pickle\n",
      "bert_768\n",
      "bow_50\n",
      "bow_768\n"
     ]
    }
   ],
   "source": [
    "evaluation_data[\"amazon\"] = {}\n",
    "\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    print('Loading result pickle: ', result_pickle)\n",
    "    with open(result_pickle, 'rb') as handle:\n",
    "        results = pickle.load(handle)    \n",
    "\n",
    "# plot\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    plot_data = {}\n",
    "       \n",
    "    for detector in detectors:\n",
    "        plot_data[detector] = []\n",
    "        for n in range(len(results[mode][detector]['predictions'][0])):\n",
    "            nth_entries = [results[mode][detector]['predictions'][i][n] for i in range(permutations)]\n",
    "            plot_data[detector].append(np.mean(nth_entries))\n",
    "            \n",
    "    evaluation_data[\"amazon\"][mode] = plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of conducted experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_words_percentage [0.    0.025 0.05  0.075 0.1   0.125 0.15  0.175 0.2   0.225 0.25  0.275\n",
      " 0.3   0.325 0.35  0.375 0.4   0.425 0.45  0.475 0.5  ]\n"
     ]
    }
   ],
   "source": [
    "target_percentages = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "negative_words_percentage = np.divide(target_percentages, 2)\n",
    "print(\"negative_words_percentage\", negative_words_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add comparison detector values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data['test'] = {}\n",
    "evaluation_data['test']['testmode'] = {}\n",
    "\n",
    "fake_predictions = [0] * 21\n",
    "fake_predictions[0] = 1\n",
    "evaluation_data['test']['testmode']['perfect'] = fake_predictions\n",
    "\n",
    "fake_predictions = [1] * 21\n",
    "fake_predictions[0] = 0\n",
    "evaluation_data['test']['testmode']['bad'] = fake_predictions\n",
    "\n",
    "fake_predictions = negative_words_percentage\n",
    "fake_predictions[0] = .012\n",
    "fake_predictions = np.divide(.01, fake_predictions)\n",
    "evaluation_data['test']['testmode']['fake'] = fake_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter bert_768 csdd 21    [0.9998 0.9998 0.9998 0.9997] ... [0.9998 0.9998 0.9998 0.9997]\n",
      "twitter bert_768 kts 21    [0.591  0.5846 0.538  0.4364] ... [0.591  0.5846 0.538  0.4364]\n",
      "twitter bert_768 aks 21    [0.5178 0.5154 0.5094 0.5009] ... [0.5178 0.5154 0.5094 0.5009]\n",
      "twitter bert_768 ammd 21    [0.547 0.532 0.453 0.347] ... [0.547 0.532 0.453 0.347]\n",
      "twitter bert_768 lsdd 21    [0.572 0.518 0.47  0.374] ... [0.572 0.518 0.47  0.374]\n",
      "twitter bert_768 cdbd 21    [0.3177 0.316  0.3141 0.3086] ... [0.3177 0.316  0.3141 0.3086]\n",
      "twitter bow_50 csdd 21    [0.9951 0.9945 0.9934 0.9918] ... [0.9951 0.9945 0.9934 0.9918]\n",
      "twitter bow_50 kts 21    [0.3424 0.2188 0.0786 0.0164] ... [0.3424 0.2188 0.0786 0.0164]\n",
      "twitter bow_50 aks 21    [0.4931 0.4776 0.4279 0.3877] ... [0.4931 0.4776 0.4279 0.3877]\n",
      "twitter bow_50 ammd 21    [0.383 0.22  0.087 0.013] ... [0.383 0.22  0.087 0.013]\n",
      "twitter bow_50 lsdd 21    [0.443 0.294 0.141 0.049] ... [0.443 0.294 0.141 0.049]\n",
      "twitter bow_50 cdbd 21    [0.1486 0.1555 0.1271 0.1311] ... [0.1486 0.1555 0.1271 0.1311]\n",
      "twitter bow_768 csdd 21    [0.9236 0.9235 0.9216 0.9161] ... [0.9236 0.9235 0.9216 0.9161]\n",
      "twitter bow_768 kts 21    [0.465  0.3772 0.1494 0.0172] ... [0.465  0.3772 0.1494 0.0172]\n",
      "twitter bow_768 aks 21    [0.4986 0.4889 0.4653 0.4328] ... [0.4986 0.4889 0.4653 0.4328]\n",
      "twitter bow_768 ammd 21    [0.436 0.281 0.123 0.054] ... [0.436 0.281 0.123 0.054]\n",
      "twitter bow_768 lsdd 21    [0.43  0.287 0.212 0.171] ... [0.43  0.287 0.212 0.171]\n",
      "twitter bow_768 cdbd 21    [0.1159 0.1029 0.1164 0.1096] ... [0.1159 0.1029 0.1164 0.1096]\n",
      "amazon bert_768 csdd 21    [0.9993 0.9993 0.9992 0.9991] ... [0.9993 0.9993 0.9992 0.9991]\n",
      "amazon bert_768 kts 21    [0.7208 0.6936 0.6286 0.5108] ... [0.7208 0.6936 0.6286 0.5108]\n",
      "amazon bert_768 aks 21    [0.5498 0.5437 0.5309 0.5109] ... [0.5498 0.5437 0.5309 0.5109]\n",
      "amazon bert_768 ammd 21    [0.742 0.736 0.643 0.523] ... [0.742 0.736 0.643 0.523]\n",
      "amazon bert_768 lsdd 21    [0.721 0.703 0.647 0.546] ... [0.721 0.703 0.647 0.546]\n",
      "amazon bert_768 cdbd 21    [0.8349 0.8388 0.8347 0.8353] ... [0.8349 0.8388 0.8347 0.8353]\n",
      "amazon bow_50 csdd 21    [0.9974 0.9973 0.9971 0.9968] ... [0.9974 0.9973 0.9971 0.9968]\n",
      "amazon bow_50 kts 21    [0.5798 0.5368 0.427  0.2852] ... [0.5798 0.5368 0.427  0.2852]\n",
      "amazon bow_50 aks 21    [0.5158 0.5121 0.5065 0.4979] ... [0.5158 0.5121 0.5065 0.4979]\n",
      "amazon bow_50 ammd 21    [0.531 0.506 0.387 0.275] ... [0.531 0.506 0.387 0.275]\n",
      "amazon bow_50 lsdd 21    [0.615 0.534 0.462 0.315] ... [0.615 0.534 0.462 0.315]\n",
      "amazon bow_50 cdbd 21    [0.2322 0.2206 0.235  0.2021] ... [0.2322 0.2206 0.235  0.2021]\n",
      "amazon bow_768 csdd 21    [0.9953 0.9953 0.9952 0.9952] ... [0.9953 0.9953 0.9952 0.9952]\n",
      "amazon bow_768 kts 21    [0.444  0.4538 0.3696 0.347 ] ... [0.444  0.4538 0.3696 0.347 ]\n",
      "amazon bow_768 aks 21    [0.5128 0.5121 0.5097 0.5058] ... [0.5128 0.5121 0.5097 0.5058]\n",
      "amazon bow_768 ammd 21    [0.557 0.553 0.502 0.446] ... [0.557 0.553 0.502 0.446]\n",
      "amazon bow_768 lsdd 21    [0.493 0.471 0.498 0.464] ... [0.493 0.471 0.498 0.464]\n",
      "amazon bow_768 cdbd 21    [0.2204 0.2156 0.1977 0.2208] ... [0.2204 0.2156 0.1977 0.2208]\n",
      "test testmode perfect 21    [1 0 0 0] ... [1 0 0 0]\n",
      "test testmode bad 21    [0 1 1 1] ... [0 1 1 1]\n",
      "test testmode fake 21    [0.8333 0.4    0.2    0.1333] ... [0.8333 0.4    0.2    0.1333]\n"
     ]
    }
   ],
   "source": [
    "for dataset in evaluation_data:\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            first = np.round(evaluation_data[dataset][mode][detector][:4], 4)\n",
    "            last = np.round(evaluation_data[dataset][mode][detector][0:4], 4)\n",
    "            print(dataset, mode, detector, len(evaluation_data[dataset][mode][detector]), \"  \", first, \"...\", last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric_ext(negative_words_percentage, p_values, factor_penalty, print_info):\n",
    "    \n",
    "    # remove first element (no injected drift)\n",
    "    neg_words_perc = negative_words_percentage[1:]\n",
    "    p_vals = p_values[1:]\n",
    "        \n",
    "    # Scores 0 (bad) to 1 (good)\n",
    "    scores = []\n",
    "    for i in range(len(p_vals)):\n",
    "        scores.append(1 - p_vals[i])\n",
    "    if(print_info):\n",
    "        print(\" difference score \", round(numpy.sum(scores), 4))\n",
    "    \n",
    "    # No injected drift in first element\n",
    "    # High penalty for low p-value\n",
    "    penalty = (1 - p_values[0]) * factor_penalty\n",
    "    for i in range(len(scores)):\n",
    "        scores[i] = (scores[i] - penalty)\n",
    "    if(print_info):\n",
    "        print(\" penalty \", round(penalty, 4), \"= 1 -\", round(p_values[0], 4))\n",
    "        print(round(numpy.sum(scores), 4), \"penalty score\")\n",
    "        \n",
    "    # Earlier drift detection is better (sensitivity)\n",
    "    sum_rating = 0\n",
    "    for i in range(len(scores)):\n",
    "        rating = 1/neg_words_perc[i]\n",
    "        sum_rating += rating\n",
    "        scores[i] = scores[i] * rating\n",
    "    \n",
    "    if(print_info):\n",
    "        print(\" scores \", numpy.round(scores, 2))\n",
    "        print(\" sum_rating \", round(sum_rating, 4))\n",
    "        print(\" result \", round(numpy.sum(scores) / sum_rating, 4))\n",
    "    \n",
    "    return np.sum(scores) / sum_rating\n",
    "\n",
    "\n",
    "def get_label(name):\n",
    "    mappings = {\n",
    "        \"cdbd\" : \"CDBD\",\n",
    "        \"csdd\" : \"CosSim\",\n",
    "        \"kts\" : \"KTS/MMD\",\n",
    "        \"aks\" : \"KS\",\n",
    "        \"lsdd\" : \"LSDD\",\n",
    "        \"ammd\" : \"MMD\",\n",
    "        \n",
    "        \"twitterbert_768\" : \"Twitter, BERT-768\",\n",
    "        \"twitterbow_50\"   : \"Twitter, BoW-50  \",\n",
    "        \"twitterbow_768\"  : \"Twitter, BoW-768 \",\n",
    "        \"amazonbert_768\"  : \"Amazon,  BERT-768\",\n",
    "        \"amazonbow_50\"    : \"Amazon,  BoW-50  \",\n",
    "        \"amazonbow_768\"   : \"Amazon,  BoW-768 \",\n",
    "    }\n",
    "    if(name in mappings):\n",
    "        return mappings[name]\n",
    "    else:\n",
    "        print(\"Unknown:\", name)\n",
    "        return name\n",
    "\n",
    "\n",
    "def get_sorted_detectors(detector_keys):\n",
    "    labels = {}\n",
    "    for detector in detectors:\n",
    "        labels[get_label(detector)] = detector\n",
    "    sorted_ = []\n",
    "    for detector in sorted(labels.keys()):\n",
    "        sorted_.append(labels[detector])\n",
    "    return sorted_\n",
    "\n",
    "\n",
    "def format_float(value):\n",
    "    rounded = np.round(value, 4)\n",
    "    if(rounded == 0): # handle -0.0\n",
    "        rounded = 0\n",
    "    return (format(rounded, '.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximim index for evaluation: 12 which is percentage 0.3\n"
     ]
    }
   ],
   "source": [
    "max_index = 12 # 20: all, 12: to 0.3\n",
    "print(\"Maximim index for evaluation:\", max_index, \"which is percentage\", negative_words_percentage[max_index])\n",
    "\n",
    "print_textbf = True\n",
    "#best_marker_start = \"\\\\textbf{\" \n",
    "#best_marker_start = \"BSLSHBSLSHtextbf{\" # backslashes could not be parsed in online tool\n",
    "#best_marker_end = \"}\"\n",
    "best_marker_start = \"\"\n",
    "best_marker_end = \"⬛\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (with penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores_with_penalty = True\n",
    "alpha = 1\n",
    "\n",
    "scores = {}\n",
    "for dataset in evaluation_data:\n",
    "    scores[dataset] = {}\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        scores[dataset][mode] = {}\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            scores[dataset][mode][detector] = eval_metric_ext(negative_words_percentage[:max_index], evaluation_data[dataset][mode][detector][:max_index], alpha, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon': {'bert_768': {'aks': 0.06345563448903337,\n",
      "                         'ammd': 0.2774584941047174,\n",
      "                         'cdbd': -0.005722064074289028,\n",
      "                         'csdd': 0.00041266540391272195,\n",
      "                         'kts': 0.2759083107357457,\n",
      "                         'lsdd': 0.24667947449902974},\n",
      "            'bow_50': {'aks': 0.04841319621666646,\n",
      "                       'ammd': 0.2558776624338497,\n",
      "                       'cdbd': 0.015567447253264647,\n",
      "                       'csdd': 0.0012872105445893261,\n",
      "                       'kts': 0.2832654896011277,\n",
      "                       'lsdd': 0.30526374373448373},\n",
      "            'bow_768': {'aks': 0.014287389881517365,\n",
      "                        'ammd': 0.16302663927082467,\n",
      "                        'cdbd': 0.016243036796248615,\n",
      "                        'csdd': 0.0003096298504931814,\n",
      "                        'kts': 0.15926182700003577,\n",
      "                        'lsdd': 0.05532434423036465}},\n",
      " 'test': {'testmode': {'bad': -1.0000000000000002,\n",
      "                       'fake': 0.6269630717570654,\n",
      "                       'perfect': 1.0000000000000002}},\n",
      " 'twitter': {'bert_768': {'aks': 0.03481322730821216,\n",
      "                          'ammd': 0.2233379006343253,\n",
      "                          'cdbd': 0.009010768071922172,\n",
      "                          'csdd': 7.738898796744768e-05,\n",
      "                          'kts': 0.2147576113055632,\n",
      "                          'lsdd': 0.2281577647613866},\n",
      "             'bow_50': {'aks': 0.13088496768943522,\n",
      "                        'ammd': 0.29414429405932324,\n",
      "                        'cdbd': 0.013279242051792265,\n",
      "                        'csdd': 0.00718466452490127,\n",
      "                        'kts': 0.25425411714111645,\n",
      "                        'lsdd': 0.3134969383559003},\n",
      "             'bow_768': {'aks': 0.09633371679136146,\n",
      "                         'ammd': 0.31452155630681755,\n",
      "                         'cdbd': 0.010177583234193868,\n",
      "                         'csdd': 0.02138811794032354,\n",
      "                         'kts': 0.3126738063098039,\n",
      "                         'lsdd': 0.2544736465886177}}}\n"
     ]
    }
   ],
   "source": [
    "if(print_scores_with_penalty):\n",
    "    pprint.pprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 1\n",
      "max_index 12\n",
      "Dataset, Model    , CDBD , KS , KTS/MMD , LSDD , $\\varnothing$ , \n",
      "Amazon,  BoW-50   , 0.0156 , 0.0484 , 0.2833 , 0.3053⬛ , 0.1631 , \n",
      "Amazon,  BoW-768  , 0.0162 , 0.0143 , 0.1593⬛ , 0.0553 , 0.0613 , \n",
      "Amazon,  BERT-768 , -0.0057 , 0.0635 , 0.2759⬛ , 0.2467 , 0.1451 , \n",
      "Twitter, BoW-50   , 0.0133 , 0.1309 , 0.2543 , 0.3135⬛ , 0.1780 , \n",
      "Twitter, BoW-768  , 0.0102 , 0.0963 , 0.3127⬛ , 0.2545 , 0.1684 , \n",
      "Twitter, BERT-768 , 0.0090 , 0.0348 , 0.2148 , 0.2282⬛ , 0.1217 , \n",
      "$\\varnothing$     ,        , 0.0098 , 0.0647 , 0.2500 , 0.2339 , "
     ]
    }
   ],
   "source": [
    "sorted_detectors = get_sorted_detectors(scores[\"twitter\"][\"bert_768\"])\n",
    "sorted_detectors.remove(\"csdd\") # Remove CosSim\n",
    "sorted_detectors.remove(\"ammd\") # Remove MMD\n",
    "sorted_datasets = sorted(scores.keys())\n",
    "sorted_modes = ['bow_50', 'bow_768', 'bert_768']\n",
    "\n",
    "print(\"alpha\", alpha)\n",
    "print(\"max_index\", max_index)\n",
    "\n",
    "# Get values to compute means\n",
    "s = {}\n",
    "c = {}\n",
    "sd = {}\n",
    "cd = {}\n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            sd[detector] = sd.get(detector,0) + score\n",
    "            cd[detector] = cd.get(detector,0) + 1\n",
    "            #if(detector == \"cdbd\" or detector == \"csdd\"): # Exclude detectors from mode mean\n",
    "            #    print(\"Skipping\", detector, \"for mode mean\")\n",
    "            #    continue\n",
    "            s[dataset+mode] = s.get(dataset+mode,0) + score\n",
    "            c[dataset+mode] = c.get(dataset+mode,0) + 1\n",
    "\n",
    "\n",
    "            \n",
    "end=\" , \"\n",
    "print(\"Dataset, Model   \", end=end)\n",
    "for detector in sorted_detectors:\n",
    "    print(get_label(detector), end=end)\n",
    "print(\"$\\\\varnothing$\", end=end) # ∅ $\\varnothing$\n",
    "    \n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        print()\n",
    "        print(get_label(dataset+mode), end=end)\n",
    "        \n",
    "        max_detector = None\n",
    "        max_score = -2\n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            if(score > max_score):\n",
    "                max_score = score\n",
    "                max_detector = detector\n",
    "                \n",
    "        for detector in sorted_detectors:\n",
    "            score = scores[dataset][mode][detector]\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_start, end=\"\")\n",
    "            print(format_float(score), end=\"\")\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_end, end=\"\")\n",
    "            print(\"\", end=end)\n",
    "            \n",
    "        print(format_float(s[dataset+mode]/c[dataset+mode]), end=end)\n",
    "\n",
    "print()\n",
    "print('$\\\\varnothing$     ,       ', end=end) # ∅ $\\varnothing$\n",
    "for detector in sorted_detectors:\n",
    "    print(format_float(sd[detector]/cd[detector]), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    pprint.pprint(s)\n",
    "    pprint.pprint(c)\n",
    "    pprint.pprint(sd)\n",
    "    pprint.pprint(cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (without penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores_without_penalty = True\n",
    "alpha = 0\n",
    "\n",
    "scoresNoPenalty = {}\n",
    "for dataset in evaluation_data:\n",
    "    scoresNoPenalty[dataset] = {}\n",
    "    for mode in evaluation_data[dataset]:\n",
    "        scoresNoPenalty[dataset][mode] = {}\n",
    "        for detector in evaluation_data[dataset][mode]:\n",
    "            scoresNoPenalty[dataset][mode][detector] = eval_metric_ext(negative_words_percentage[:max_index], evaluation_data[dataset][mode][detector][:max_index], alpha, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon': {'bert_768': {'aks': 0.5136749080562332,\n",
      "                         'ammd': 0.5354584941047175,\n",
      "                         'cdbd': 0.15933405726829214,\n",
      "                         'csdd': 0.001088462866376101,\n",
      "                         'kts': 0.5551083107357456,\n",
      "                         'lsdd': 0.5256795034668872},\n",
      "            'bow_50': {'aks': 0.532659628997886,\n",
      "                       'ammd': 0.7248776624338498,\n",
      "                       'cdbd': 0.7833480057564469,\n",
      "                       'csdd': 0.003905046543124483,\n",
      "                       'kts': 0.7034654896011276,\n",
      "                       'lsdd': 0.6902637625099467},\n",
      "            'bow_768': {'aks': 0.5014536157917042,\n",
      "                        'ammd': 0.6060266392708246,\n",
      "                        'cdbd': 0.7958606837503333,\n",
      "                        'csdd': 0.004977865629301775,\n",
      "                        'kts': 0.7152618270000358,\n",
      "                        'lsdd': 0.562324353945922}},\n",
      " 'test': {'testmode': {'bad': 0.0,\n",
      "                       'fake': 0.7936297384237321,\n",
      "                       'perfect': 1.0000000000000002}},\n",
      " 'twitter': {'bert_768': {'aks': 0.5169832130793913,\n",
      "                          'ammd': 0.6763379006343253,\n",
      "                          'cdbd': 0.6913468754658383,\n",
      "                          'csdd': 0.0003069264749974769,\n",
      "                          'kts': 0.6237576113055632,\n",
      "                          'lsdd': 0.6561577768015249},\n",
      "             'bow_50': {'aks': 0.6377421840476201,\n",
      "                        'ammd': 0.9111442940593233,\n",
      "                        'cdbd': 0.8646329891192347,\n",
      "                        'csdd': 0.01211313418279922,\n",
      "                        'kts': 0.9118541171411166,\n",
      "                        'lsdd': 0.8704969512379542},\n",
      "             'bow_768': {'aks': 0.5977448567564189,\n",
      "                         'ammd': 0.8785215563068176,\n",
      "                         'cdbd': 0.8942612074597236,\n",
      "                         'csdd': 0.09775913205851813,\n",
      "                         'kts': 0.847673806309804,\n",
      "                         'lsdd': 0.8244736578762474}}}\n"
     ]
    }
   ],
   "source": [
    "if(print_scores_without_penalty):\n",
    "    pprint.pprint(scoresNoPenalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0\n",
      "max_index 12\n",
      "Dataset, Model    , CDBD , KS , KTS/MMD , LSDD , $\\varnothing$ , \n",
      "Amazon,  BoW-50   , 0.7833⬛ , 0.5327 , 0.7035 , 0.6903 , 0.6774 , \n",
      "Amazon,  BoW-768  , 0.7959⬛ , 0.5015 , 0.7153 , 0.5623 , 0.6437 , \n",
      "Amazon,  BERT-768 , 0.1593 , 0.5137 , 0.5551⬛ , 0.5257 , 0.4384 , \n",
      "Twitter, BoW-50   , 0.8646 , 0.6377 , 0.9119⬛ , 0.8705 , 0.8212 , \n",
      "Twitter, BoW-768  , 0.8943⬛ , 0.5977 , 0.8477 , 0.8245 , 0.7910 , \n",
      "Twitter, BERT-768 , 0.6913⬛ , 0.5170 , 0.6238 , 0.6562 , 0.6221 , \n",
      "$\\varnothing$     ,        , 0.6981 , 0.5500 , 0.7262 , 0.6882 , "
     ]
    }
   ],
   "source": [
    "sorted_detectors = get_sorted_detectors(scores[\"twitter\"][\"bert_768\"])\n",
    "sorted_detectors.remove(\"csdd\") # Remove CosSim\n",
    "sorted_detectors.remove(\"ammd\") # Remove MMD\n",
    "sorted_datasets = sorted(scores.keys())\n",
    "sorted_modes = ['bow_50', 'bow_768', 'bert_768']\n",
    "\n",
    "print(\"alpha\", alpha)\n",
    "print(\"max_index\", max_index)\n",
    "\n",
    "# Get values to compute means\n",
    "s = {}\n",
    "c = {}\n",
    "sd = {}\n",
    "cd = {}\n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        for detector in sorted_detectors:\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            sd[detector] = sd.get(detector,0) + score\n",
    "            cd[detector] = cd.get(detector,0) + 1\n",
    "            #if(detector == \"cdbd\" or detector == \"csdd\"): # Exclude detectors from mode mean\n",
    "            #    print(\"Skipping\", detector, \"for mode mean\")\n",
    "            #    continue\n",
    "            c[dataset+mode] = c.get(dataset+mode,0) + 1\n",
    "            s[dataset+mode] = s.get(dataset+mode,0) + score\n",
    "\n",
    "\n",
    "            \n",
    "end=\" , \"\n",
    "print(\"Dataset, Model   \", end=end)\n",
    "for detector in sorted_detectors:\n",
    "    print(get_label(detector), end=end)\n",
    "print(\"$\\\\varnothing$\", end=end) # ∅ $\\varnothing$\n",
    "    \n",
    "for dataset in sorted_datasets:\n",
    "    if(dataset == \"test\"):\n",
    "        continue\n",
    "    for mode in sorted_modes:\n",
    "        print()\n",
    "        print(get_label(dataset+mode), end=end)\n",
    "        \n",
    "        max_detector = None\n",
    "        max_score = -2\n",
    "        for detector in sorted_detectors:\n",
    "            #if(detector == \"cdbd\"): # exclude from max scores\n",
    "            #    continue\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            if(score > max_score):\n",
    "                max_score = score\n",
    "                max_detector = detector\n",
    "\n",
    "        for detector in sorted_detectors:\n",
    "            score = scoresNoPenalty[dataset][mode][detector]\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_start, end=\"\")\n",
    "            print(format_float(score), end=\"\")\n",
    "            if(print_textbf and detector == max_detector):\n",
    "                print(best_marker_end, end=\"\")\n",
    "            print(\"\", end=end)\n",
    "            \n",
    "        print(format_float(s[dataset+mode]/c[dataset+mode]), end=end)\n",
    "\n",
    "print()\n",
    "print('$\\\\varnothing$     ,       ', end=end) # ∅ $\\varnothing$\n",
    "for detector in sorted_detectors:\n",
    "    print(format_float(sd[detector]/cd[detector]), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    pprint.pprint(s)\n",
    "    pprint.pprint(c)\n",
    "    pprint.pprint(sd)\n",
    "    pprint.pprint(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EML4U)",
   "language": "python",
   "name": "eml4u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

