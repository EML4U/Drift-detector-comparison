{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift experiments\n",
    "\n",
    "Executes detectors on different models and saves results in the format:\n",
    "\n",
    "```\n",
    "{'data_id': {'detector_id': {'predictions': [.1,.2,.3],\n",
    "                             'time_detect': 60.00,\n",
    "                             'time_fit': 1.00}}}\n",
    "```\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "# Set data paths\n",
    "config          = yaml.safe_load(open(\"config.yaml\", \"r\"))\n",
    "bow_50_file  = os.path.join(config[\"EMBEDDINGS_DIRECTORY\"], \"amazon_drift_bow_50.pickle\")\n",
    "bow_768_file = os.path.join(config[\"EMBEDDINGS_DIRECTORY\"], \"amazon_drift_bow_768.pickle\")\n",
    "results_file = os.path.join(config[\"EXPERIMENTS_DIRECTORY\"], \"results_a\")\n",
    "print(\"bow_50_file\", bow_50_file)\n",
    "print(\"bow_768_file\", bow_768_file)\n",
    "\n",
    "# Load data\n",
    "data = {}\n",
    "with open(bow_50_file, \"rb\") as handle:\n",
    "    data[\"bow_50\"] = pickle.load(handle)\n",
    "print(\"Samples:\", len(data[\"bow_50\"]['orig'][0]), len(data[\"bow_50\"]['drifted'][0][0]), len(data[\"bow_50\"]['train'][0]))\n",
    "with open(bow_768_file, \"rb\") as handle:\n",
    "    data[\"bow_768\"] = pickle.load(handle)\n",
    "print(\"Samples:\", len(data[\"bow_768\"]['orig'][0]), len(data[\"bow_768\"]['drifted'][0][0]), len(data[\"bow_768\"]['train'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print example data\n",
    "if(False):\n",
    "    print_model = data[\"bow_50\"]\n",
    "    print(type(print_model), len(print_model))\n",
    "    for key, value in print_model.items() :\n",
    "        print (key, type(value), len(value))\n",
    "        for i in range(len(value)) :\n",
    "            print (value[i][0])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous results\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, \"rb\") as handle:\n",
    "        results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Call fit funtion, if not already in results\n",
    "def default_fit(detector_id, detector, data_id, data, results, force_run):\n",
    "    if(data_id in results and detector_id in results[data_id] and not force_run):\n",
    "        return\n",
    "    \n",
    "    # Reset results\n",
    "    results_detector = {}\n",
    "    \n",
    "    time_begin = time.time()\n",
    "        \n",
    "    detector.fit(data)\n",
    "    \n",
    "    results_detector[\"time_fit\"] = time.time() - time_begin\n",
    "    \n",
    "    if(data_id not in results):\n",
    "        results[data_id] = {}\n",
    "    results[data_id][detector_id] = results_detector\n",
    "\n",
    "# Compute predictions, if not already in results\n",
    "def default_detect(detector_id, detector, data_id, data, results, force_run):\n",
    "    if(data_id in results and detector_id in results[data_id] and\n",
    "       \"predictions\" in results[data_id][detector_id] and not force_run):\n",
    "        return\n",
    "    \n",
    "    # Get previous results\n",
    "    if(data_id in results and detector_id in results[data_id]):\n",
    "        results_detector = results[data_id][detector_id]\n",
    "    else:\n",
    "        results_detector = {}\n",
    "    \n",
    "    time_begin = time.time()\n",
    "    \n",
    "    results_detector[\"predictions\"] = []\n",
    "    print(data_id, detector_id, end=\" \")\n",
    "    for p in data:\n",
    "        results_detector[\"predictions\"].append(detector.predict_proba(p))\n",
    "        print(len(p) , end=\" \")\n",
    "    print()\n",
    "\n",
    "    results_detector[\"time_detect\"] = time.time() - time_begin\n",
    "\n",
    "    if(data_id not in results):\n",
    "        results[data_id] = {}\n",
    "    results[data_id][detector_id] = results_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.AlibiKSDetector import AlibiKSDetector\n",
    "detector_id = \"AlibiKSDetector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_50\"\n",
    "detector = AlibiKSDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_768\"\n",
    "detector = AlibiKSDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.AlibiMMDDetector import AlibiMMDDetector\n",
    "detector_id = \"AlibiMMDDetector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_50\"\n",
    "detector = AlibiMMDDetector(backend = 'pytorch')\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_768\"\n",
    "detector = AlibiMMDDetector(backend = 'pytorch')\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.CosineDetector import CosineSimilarityDriftDetector\n",
    "detector_id = \"CosineDetector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_50\"\n",
    "detector = CosineSimilarityDriftDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_768\"\n",
    "detector = CosineSimilarityDriftDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.FCITDetector import FCITDriftDetector\n",
    "detector_id = \"FCITDetector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_50\"\n",
    "detector = FCITDriftDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_768\"\n",
    "detector = FCITDriftDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.KernelTwoSampleDetector import KernelTwoSampleDriftDetector\n",
    "detector_id = \"KernelTwoSampleDetector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_50\"\n",
    "detector = KernelTwoSampleDriftDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_768\"\n",
    "detector = KernelTwoSampleDriftDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.AlibiLSDD import AlibiLSDDDetector\n",
    "detector_id = \"AlibiLSDDDetector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_50\"\n",
    "detector = AlibiLSDDDetector(backend='pytorch')\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_768\"\n",
    "detector = AlibiLSDDDetector(backend='pytorch')\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.AlibiChiSquaredDetector import AlibiChiSquaredDetector\n",
    "detector_id = \"AlibiChiSquaredDetector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_50\"\n",
    "detector = AlibiChiSquaredDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_768\"\n",
    "detector = AlibiChiSquaredDetector()\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.AlibiChiSquaredDetector import AlibiChiSquaredDetector\n",
    "detector_id = \"AlibiChiSquaredDetector-FDR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_50\"\n",
    "detector = AlibiChiSquaredDetector(correction = \"fdr\")\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_768\"\n",
    "detector = AlibiChiSquaredDetector(correction = \"fdr\")\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, False)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.CDBDDetector import CDBDDetector\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "detector_id = \"CDBDDetector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"bow_50\"\n",
    "\n",
    "features = data[data_id]['train'][0]\n",
    "targets = np.array(data[data_id]['train'][1])[:,1] # take the labels from dictionary, convert to np.array and slice to only get the scores\n",
    "targets = targets.astype('int')\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, targets, test_size=0.33, shuffle=False)\n",
    "model = SVC(kernel='linear', random_state=42) # SVM model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "detector = CDBDDetector(model)\n",
    "default_fit   (detector_id, detector, data_id, data[data_id]['orig'][0],    results, True)\n",
    "default_detect(detector_id, detector, data_id, data[data_id]['drifted'][0], results, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open(results_file, \"wb\") as handle:\n",
    "    pickle.dump(results, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "if(True):\n",
    "    print(\"Runtimes (fit and detect) in minutes:\")\n",
    "    from pprint import pprint\n",
    "    for data_id in results:\n",
    "        times = {}\n",
    "        for detector_id in results[data_id]:\n",
    "            time = 0\n",
    "            for key in results[data_id][detector_id]:\n",
    "                if(key == \"time_detect\" or key == \"time_fit\"):\n",
    "                    time += results[data_id][detector_id][key]\n",
    "            times[detector_id] = time/60\n",
    "        pprint(sorted(times.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "if(True):\n",
    "    from pprint import pprint\n",
    "    pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EML4U)",
   "language": "python",
   "name": "eml4u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

